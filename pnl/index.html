<HTML>
<HEAD>


<TITLE>OSU Perception and Neurodynamics Lab </TITLE>
<META NAME="DeLiang Wang" CONTENT="perception" "neurodynamics">


<STYLE>

BODY {background:#A5DE94}

A:LINK {color:#218429}
A:VISITED {color:#218429}

FONT {color:#218429; font-weight:bold}
H2 {color:#218429; font-weight:bold; font-size:12pt}


H1 {color:#FF6342;font-weight:bold;font-size:18pt; text-align:center}
H3 {color:#FF6342;font-weight:bold; font-style:italic; font-size:14pt;
    text-align:center}

H4 {color:#D60000; letter-spacing:2pt; font-weight:bold; font-style:italic; font-size:12pt;
    text-align:center}

P {color:#184A18; font-size:11pt}

UL {list-style:disc; color:#218429}

</STYLE>
</HEAD>


<BODY LEFTMARGIN=0 TOPMARGIN=10 MARGINWIDTH=0 MARGINHEIGHT=0>


<table width="100%" border=0 cellspacing=0 cellpadding=5>
  <tr> 
    	<TD WIDTH=128>&nbsp</TD>

<!--    	<TD ALIGN="left"><A HREF="projects.html"><H2>Projects</H2></A></TD>
-->
	<TD ALIGN="center"><A HREF="software.html"><H2>Software</H2></A></TD>

	<TD ALIGN="center"><A HREF="data.html"><H2>Data</H2></A></TD>

	<TD ALIGN="center"><A HREF="demo.html"><H2>Sound demos</H2></A></TD>

	<TD ALIGN="center"><A HREF="links.html"><H2>Useful links</H2></A></TD>

	<TD ALIGN="center"><A HREF="contact.html"><H2>Contact</H2></A></TD>
  </tr>


  <tr>
    <td WIDTH=128 ALIGN="center" VALIGN="top">
	
<!--	<A HREF="blurp.html"><H4>Open GRA Position</H4></A>
-->
	<FONT>
	Publications<BR>
                        <A TARGET=_blank HREF="https://pnlwang.github.io/pubs_year.html">
			<I>By Year</I><BR></A>
                        <A TARGET=_blank HREF="https://pnlwang.github.io/pubs_topic.html">
			<I>By Topic</I></A>

	
	<BR><BR>
	Members<BR>

                        <A TARGET='blank' HREF="https://pnlwang.github.io">
				<I>Prof. D. Wang</I><BR></A>
					
						<A TARGET='blank' HREF="https://www.linkedin.com/in/vahid-ahmadi">
				<I>V. A. Kalkhorani</I><BR></A>
				
                        <A TARGET='blank' HREF="https://yfyangseu.github.io">
				<I>Y. Yang</I><BR></A>

						<A TARGET='blank' HREF="https://www.linkedin.com/in/williamchengyu">
				<I>C. Yu</I><BR></A>

	<BR>
	<A HREF="alumni.html">Alumni</A>

	<BR><BR>
	<A HREF="visitor.html">Visitors</A>

	<BR><BR>
	<A HREF="theses.html">Theses</A>

	<BR><BR>
	<A HREF="index.html">Home</A>

	</FONT>
    </TD>

    <td COLSPAN=6 BACKGROUND="https://pnlwang.github.io/my_images/uback.gif">
	<BR>
<H1>Perception and Neurodynamics Laboratory (PNL)</H1>
<H3>
Affiliated with <a target=_blank href="https://web.cse.ohio-state.edu/lair">OSU Laboratory for
AI Research (LAIR)</a>,
<a target=_blank HREF="https://cse.osu.edu/">Department of Computer Science 
and Engineering (CSE)</a>,
and <a target=_blank HREF="https://cog.osu.edu/">Center for Cognitive and Brain Sciences</a>
</H3>
</CENTER>

<P>
This lab conducts research on developing effective algorithms
for solving real-world problems related to machine perception as well
as understanding neurocomputational
mechanisms underlying perceptual processes. We view
these two aspects of our goal as intimately related, as we believe that
information-processing mechanisms of the brain as the product of millions
of years of evolution represent the <B>optimal</B> or <B>near-optimal</B>
computational algorithms,
and conversely the computational algorithms that ultimately work for
modeling perception will be <B>closely related to</B> what actually are used 
by the brain.

<P>
The general strategy adopted by this lab is to focus on challenging problems
that arise from real-world perception, and then attack them with
multidisciplinary approaches. The analysis includes computational,
cognitive/perceptual, and neurobiological perspectives.
While paying
close attention to cognitive and neurobiological processes, the thrust of
the work conducted in this lab is <B>computational</B>. 

<P> 
Recent work in the lab focuses on machine learning algorithms, particularly deep neural networks 
(DNNs), for auditory scene analysis. In order to achieve the ultimate goal of 
constructing a cocktail party processor that achieves the human ability in 
cocktail party environments, one must understand individual analyses, 
such as pitch, location, amplitude and frequency modulation, 
onset/offset, rhythm, and so on. One must also incorporate 
top-down information including attention and recognition. The lab 
conducts research on a variety of topics under the general theme 
of computational audition, including speech separation and robust automatic speech/speaker 
recognition. For example, this lab has originated 
the notion of the ideal binary mask (<A HREF="https://pnlwang.github.io/papers/Wang05.pdf">Wang, 2005</a>), which formulates sound segregation as a 
classification problem. This formulation has enabled the use of supervised 
learning to address the source separation problem (known as supervised separation). This lab is the first to introduce DNN to the domain of speech separation or enhancement (<A HREF="https://pnlwang.github.io/papers/Wang-Wang.taslp13.pdf">Wang
& Wang, 2013</a>), and the resulting DNN based algorithm produced,
for the first time, substantial speech intelligiblity improvements for hearing-impaired 
listeners in background noise (<A HREF="https://pnlwang.github.io/papers/HYWW.jasa13.pdf">Healy et al., 2013</a>; see <a href="http://researchnews.osu.edu/archive/cocktailparty.htm">
Press Release</a>, <a href="https://www.youtube.com/watch?v=tBNpglPHQsY">YouTube Demo</a>, and <a href="https://pnlwang.github.io/pnl/corpus/Healy-jasa13/YWang.html">Test Data</a>.)

<P>
In terms of neurodynamics, we
view the brain as a gigantic dynamical system, and we build dynamical systems
for solving engineering problems and for understanding
neurocomputational mechanisms. To illustrate this strategy, 
LEGION (Locally Excitatory
Globally Inhibitory Oscillator Networks) invented by David Terman
and DeLiang Wang (<A HREF="https://pnlwang.github.io/papers/Terman-Wang95.pdf">Terman & Wang,
1995</a>, <A HREF="https://pnlwang.github.io/papers/Wang-Terman.tnn95.pdf">Wang & Terman, 1995</a>)
builds on neural oscillations in the brain and perceptual organization
in human perception. The network shows remarkable computational power in
synchronizing a locally coupled oscillator population and
desynchronizing different populations. The LEGION network has been applied to
image segmentation (see <A HREF="https://pnlwang.github.io/papers/Wang-Terman97.pdf">Wang
& Terman, 1997</a>) and speech segregation
(see <A HREF="https://pnlwang.github.io/papers/Wang-Brown.tnn99.pdf">Wang
& Brown, 1999</a>), among other
applications. The following figures show the input (left)
to LEGION and the output (right) generated from LEGION
(see <A HREF="https://pnlwang.github.io/papers/Wang.tnn05.pdf">Wang, 2005</a>, for an extensive review on
this effort).
<br><br><br>

<CENTER>
<P>
<IMG HEIGHT=257 WIDTH=257 SRC="https://pnlwang.github.io/images/brain.gif">  ==LEGION==>
<IMG HEIGHT=257 WIDTH=257 SRC="https://pnlwang.github.io/images/brain-seg.gif">
<BR><BR>
<IMG HEIGHT=210 WIDTH=257 SRC="https://pnlwang.github.io/images/v8n6-rate.gif">  ==LEGION==>
<IMG HEIGHT=210 WIDTH=257 SRC="https://pnlwang.github.io/images/v8n6-seg.gif">

<BR><BR><BR>
(The above acoustic mixture is composed of phone ringing and male utterance
"Why were you all weary")
<BR>
</CENTER>
   
    </td>
  </tr>

</table>

</BODY>
</HTML>
