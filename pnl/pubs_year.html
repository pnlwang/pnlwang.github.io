<HTML>
<HEAD>


<TITLE>DeLiang Wang's Publications by Year</TITLE>
<META NAME="DeLiang Wang" CONTENT="publications, DeLiang Wang, 
D.L. Wang, D. Wang, pnl, year">


<STYLE>

BODY {background:#A5DE94}

A:LINK {color:#218429}
A:VISITED {color:#218429}

FONT {color:#218429; font-weight:bold}
FONT2 {color:#FF6342; font-weight:bold}
H2 {color:#218429; font-weight:bold; font-size:12pt}
H1 {color:#FF6342; font-weight:bold; font-size:16pt;
    text-align:center}
H3 {color:#FF6342; font-weight:bold; font-style:italic; font-size:14pt;
    text-align:center}

H5 {color:#218429;font-size:11pt; font-weight:normal;font-style:normal;
    text-align:right} 
H6 {font-size:11pt}
DD {color:#218429; font-size:11pt} epor

P {color:#218429}

UL {list-style:disc; color:#218429}

</STYLE>

</HEAD>


<BODY LEFTMARGIN=0 TOPMARGIN=0 MARGINWIDTH=0 MARGINHEIGHT=0>

<table width="100%" border=0 cellspacing=0 cellpadding=5>
  <tr> 
   
<TD ALIGN="center">
<a href="pubs_year.html#article"><H2>Journal Articles</H2></a>
</TD>  
<TD ALIGN="center">
<a href="pubs_year.html#chapter"><H2>Book Chapters</H2></a>
</TD>
<TD ALIGN="center">
<a href="pubs_year.html#paper"><H2>Conference Papers</H2></a>
</TD>
<TD ALIGN="center">
<a href="pubs_year.html#report"><H2>Technical Reports</H2></a>	
</TD>

  </tr>


  <tr>
    
    <td COLSPAN=4 BGCOLOR="#FFFFFF">

<p>
<H1>Publications in Reverse Chronological Order</H1>
<center>
<pre><DD>[<a href="https://web.cse.ohio-state.edu/~dwang/pubs_topic.html">Publications by topic</a>]      [<a href="https://web.cse.ohio-state.edu/~dwang/">DeLiang Wang</a>]     [<a href="https://pnlwang.github.io/pnl/">Laboratory</a>]</DD></pre>
</center>

<!-- ######################## -->

<a Name = "article"></a>

<H3>Journal Articles</H3>

<UL>

<LI>Taherian H., Tan K., and Wang D.L. (2022): 
<A HREF="papers/TTW.taslp22.pdf">
Multi-channel talker-independent speaker separation through location-based training</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 30, pp. 2791-2800.
<br><br>

<LI>Zhang H. and Wang D.L. (2022): 
<A HREF="papers/Zhang-Wang.taslp22.pdf">
Neural cascade architecture multi-channel acoustic echo suppression</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 30, pp. 2326-2336.
<br><br>

<LI>Pandey A. and Wang D.L. (2022): 
<A HREF="papers/Pandey-Wang.taslp22.pdf">
Self-attending RNN for speech enhancement to improve cross-corpus generalization</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 30, pp. 1374-1385.
<br><br>

<LI>Wang H. and Wang D.L. (2022): 
<A HREF="papers/Wang-Wang.taslp22.pdf">
Neural cascade architecture with triple-domain loss for speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 30, pp. 734-743.
<br><br>

<LI>Tan K., Wang Z.-Q., and Wang D.L. (2022): 
<A HREF="papers/TWW.taslp22.pdf">
Neural spectrospatial filtering</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 30, pp. 605-621.
<br><br>

<LI>Healy E.W., Taherian H., Johnson E.M., and Wang D.L. (2021): 
<A HREF="papers/HTJW.jasa21b.pdf">
A causal and talker-independent speaker separation/dereverberation deep learning algorithm: Cost associated 
with conversion to real-time capable operation</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 150, pp. 3976-3986.
<br><br>

<LI>Healy E.W., Johnson E.M., Delfarah M., Krishnagiri D.S., Sevich V.A., Taherian H., and Wang D.L. (2021): 
<A HREF="papers/HealyEtAl.jasa21.pdf">
Deep learning based speaker separation and dereverberation can generalize across different languages to improve intelligibility</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 150, pp. 2526-2538.
<br><br>

<LI>Li H., Wang D.L., Zhang X., Gao G. (2021): 
<A HREF="papers/LWZG.taslp21.pdf">
Recurrent neural networks and acoustic features for frame-level signal-to-noise ratio estimation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 2878-2887.
<br><br>

<LI>Wang H. and Wang D.L. (2021): 
<A HREF="papers/Wang-Wang.taslp21.pdf">
Towards robust speech super-resolution</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 2058-2066.
<br><br>

<LI>Wang Z.-Q., Wang P., and Wang D.L. (2021): 
<A HREF="papers/WWW.taslp21.pdf">
Multi-microphone complex spectral mapping for utterance-wise and continuous speech separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 2001-2014.
<br><br>

<LI>Zhang H. and Wang D.L. (2021): 
<A HREF="papers/Zhang-Wang.nn21.pdf">
Deep ANC: A deep learning approach to active noise control</a>.
<cite>Neural Networks</cite>, vol. 141, pp. 1-10.
<br><br>

<LI>Healy E.W., Tan K., Johnson E.M., and Wang D.L. (2021): 
<A HREF="papers/HTJW.jasa21.pdf">
An effectively causal deep learning algorithm to increase intelligibility in untrained noises for hearing-impaired listeners</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 149, pp. 3943–3953.
<br><br>

<LI>Tan K., Zhang X., and Wang D.L. (2021): 
<A HREF="papers/TZW.taslp21.pdf">
Deep learning based real-time speech enhancement for dual-microphone mobile phones</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 1853-1863.
<br><br>

<LI>Tan K. and Wang D.L. (2021): 
<A HREF="papers/Tan-Wang.taslp21.pdf">
Towards model compression for deep learning based speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 1785-1794.
<br><br>

<LI>Pandey A. and Wang D.L. (2021): 
<A HREF="papers/Pandey-Wang.taslp21.pdf">
Dense CNN with self-attention for time-domain speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 1270-1279.
(Related <a href="https://pnlwang.github.io/pnl/demo.html">Sound Demo</a>.)
<br><br>

<LI>Wang P., Chen Z., Wang D.L., Li J., and Gong Y. (2021): 
<A HREF="papers/WCWLG.taslp21.pdf">
Speaker separation using speaker inventories and estimated speech</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 29, pp. 537-546.
<br><br>

<LI>Pandey A. and Wang D.L. (2020): 
<A HREF="papers/Pandey-Wang.taslp20.pdf">
On cross-corpus generalization of deep learning based speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 2489-2499.
<br><br>

<LI>Delfarah M., Liu Y. and Wang D.L. (2020): 
<A HREF="papers/DLW.jasa20.pdf">
A two-stage deep learning algorithm for talker-independent speaker separation in reverberant conditions</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 148, pp. 1157-1168.
<br><br>

<LI>Liu Y. and Wang D.L. (2020): 
<A HREF="papers/Liu-Wang.taslp20.pdf">
Causal deep CASA for monaural talker-independent speaker separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 2109-2118. 
<br><br>

<LI>Wang Z.-Q., Wang P., and Wang D.L. (2020): 
<A HREF="papers/WWW.taslp20.pdf">
Complex spectral mapping for single- and multi-channel speech enhancement and robust ASR</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 1778-1787.
<br><br>

<LI>Zhao Y., Wang D.L., Xu B., and Zhang T. (2020): 
<A HREF="papers/ZWXZ.taslp20.pdf">
Monaural speech dereverberation using temporal convolutional networks with self attention</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 1598-1607.
<br><br>

<LI>Healy E.W., Johnson E.M., Delfarah M., and Wang D.L. (2020): 
<A HREF="papers/HJDW.jasa20.pdf">
A talker-independent deep learning algorithm to increase intelligibility for hearing-impaired listeners in reverberant competing talker conditions</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 147, pp. 4106-4118.
<br><br>

<LI>Taherian H., Wang Z.-Q., Chang J., and Wang D.L. (2020): 
<A HREF="papers/TWCW.taslp20.pdf">
Robust speaker recognition based on single-channel and multi-channel speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 1293-1302.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2020): 
<A HREF="papers/Wang-Wang.taslp20.pdf">
Deep learning based target cancellation for speech dereverberation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 941-950.
<br><br>

<LI>Tan K. and Wang D.L. (2020): 
<A HREF="papers/Tan-Wang.taslp20.pdf">
Learning complex spectral mapping with gated convolutional recurrent networks for monaural speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 380-390.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Wang P., Tan K., and Wang D.L. (2020): 
<A HREF="papers/WTW.taslp20.pdf">
Bridging the gap between monaural speech enhancement and recognition with distortion-independent acoustic modeling</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 28, pp. 39-48.
<br><br>

<LI>Liu Y. and Wang D.L. (2019): 
<A HREF="papers/Liu-Wang.taslp19.pdf">
Divide and conquer: A deep CASA approach to talker-independent monaural speaker separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 2092-2102. 
(<a HREF="https://github.com/yuzhou-git/deep-casa">Tensorflow Code and Description in GitHub</a>.)
<br><br>

<LI>Delfarah M. and Wang D.L. (2019): 
<A HREF="papers/Delfarah-Wang.taslp19.pdf">
Deep learning for talker-dependent reverberant speaker separation: An empirical study</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 1839-1848.
<br><br>

<LI>Healy E.W., Vasco J.L., and Wang D.L. (2019): 
<A HREF="papers/HVW.jasaEL19.pdf">
The optimal threshold for removing noise from speech is similar across normal and impaired hearing — a time-frequency masking study</a>.
<cite>Journal of the Acoustical Society of America Express Letters</cite>, vol. 145, pp. EL581-586.
<br><br>

<LI>Pandey A. and Wang D.L. (2019): 
<A HREF="papers/Pandey-Wang.taslp19.pdf">
A new framework for CNN-based speech enhancement in the time domain</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 1179-1188.
<br><br>

<LI>Healy E.W., Delfarah M., Johnson E.M., and Wang D.L. (2019): 
<A HREF="papers/HDJW.jasa19.pdf">
A deep learning algorithm to increase intelligibility for hearing-impaired listeners in the presence of a competing talker and reverberation</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 145, pp. 1378-1388.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2019): 
<A HREF="papers/Wang-Wang.taslp19.pdf">
Combining spectral and spatial features for deep learning based blind speaker separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 457-468.
<br><br>

<LI>Tan K., Chen J., and Wang D.L. (2019): 
<A HREF="papers/TCW.taslp19.pdf">
Gated residual networks with dilated convolutions for monaural speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 189-198.
<br><br>

<LI>Wang Z.-Q., Zhang X., and Wang D.L. (2019): 
<A HREF="papers/WZW.taslp19.pdf">
Robust speaker localization guided by deep learning-based time-frequency masking</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 178-188.
<br><br>

<LI>Zhao Y., Wang Z.-Q., and Wang D.L. (2019): 
<A HREF="papers/ZWW.taslp19.pdf">
Two-stage deep learning for noisy-reverberant speech enhancement</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 27, pp. 53-62.
<br><br>

<LI>Zhao Y., Wang D.L., Johnson E.M., and Healy E.W.  (2018): 
<A HREF="papers/ZWJH.jasa18.pdf">
A deep learning based segregation algorithm to increase speech intelligibility for hearing-impaired listeners in reverberant-noisy conditions</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 144, pp. 1627-1637.
<br><br>

<LI>Wang D.L. and Chen J. (2018): 
<A HREF="papers/Wang-Chen.taslp18.pdf">
Supervised speech separation based on deep learning: An overview</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 26, pp. 1702-1726.
<br><br>

<LI>Williamson D.S. and Wang D.L. (2017): 
<A HREF="papers/Williamson-Wang.taslp17.pdf">
Time-frequency masking in the complex domain for speech dereverberation and denoising</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 25, pp. 1492-1501.
<br><br>

<LI>Chen J. and Wang D.L. (2017): 
<A HREF="papers/Chen-Wang.jasa17.pdf">
Long short-term memory for speaker generalization in supervised speech separation</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 141, pp. 4705-4714.
<br><br>

<LI>Mayer F., Williamson D.S., Mowlaee P., and Wang D.L. (2017): 
<A HREF="papers/MWMW.jasa17.pdf">
Impact of phase estimation on single-channel speech separation based on time-frequency masking</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 141, pp. 4668-4679.
<br><br>

<LI>Healy E.W., Delfarah M., Vasko J.L., Carter B.L., and Wang D.L. (2017):
<a href="papers/HDVCW.jasa17.pdf">
An algorithm to increase intelligibility for hearing-impaired listeners in the presence of a competing talker</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 141, pp. 4230-4239.
<br><br>

<LI>Delfarah M. and Wang D.L. (2017): 
<A HREF="papers/Delfarah-Wang.taslp17.pdf">
Features for masking-based monaural speech separation in reverberant conditions</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 25, pp. 1085-1094.
<br><br>

<LI>Zhang X. and Wang D.L. (2017): 
<A HREF="papers/Zhang-Wang.taslp17.pdf">
Deep learning based binaural speech separation in reverberant environments</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 25, pp. 1075-1084.
<br><br>

<LI>Wang D.L. (2017): 
<A HREF="http://spectrum.ieee.org/consumer-electronics/audiovideo/deep-learning-reinvents-the-hearing-aid">
Deep learning reinvents the hearing aid</a>.
<cite>IEEE Spectrum</cite>, March Issue, pp. 32-37 (<FONT2>Cover Story</FONT2>).
<br><br>

<LI>Liu Y. and Wang D.L. (2017): 
<A HREF="papers/Liu-Wang.jasa17.pdf">
Speaker-dependent multipitch tracking using deep neural networks</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 141, pp. 710-721.
<br><br>

<LI>Chen J., Wang Y., Yoho S.E., Wang D.L., and Healy E.W. (2016):
<a href="papers/CWYWH.jasa16.pdf">
Large-scale training to increase speech intelligibility for hearing-impaired listeners in novel noises</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 139, pp. 2604-2612.
<br><br>

<LI>Zhang X.-L. and Wang D.L. (2016): 
<A HREF="papers/Zhang-Wang.taslp16_2.pdf">
A deep ensemble learning method for monaural speech separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 24, pp. 967-977.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2016): 
<A HREF="papers/Wang-Wang.taslp16.pdf">
A joint training framework for robust automatic speech recognition</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 24, pp. 796-806.
<br><br>

<LI>Williamson D.S., Wang Y., and Wang D.L. (2016): 
<A HREF="papers/WWW.taslp16.pdf">
Complex ratio masking for monaural speech separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 24, pp. 483-492.
<br><br>

<LI>Chen J., Wang Y., and Wang D.L. (2016):
<a href="papers/CWW.spcomm16.pdf">
Noise perturbation for supervised speech separation</a>.
<cite>Speech Communication</CITE>, vol. 78, pp. 1-10.
<br><br>

<LI>Zhang X.-L. and Wang D.L. (2016): 
<A HREF="papers/Zhang-Wang.taslp16_1.pdf">
Boosting contextual information for deep neural network based voice activity detection</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</cite>, vol. 24, pp. 252-264.
<br><br>

<LI>Healy E.W., Yoho S.E., Chen J., Wang Y., and Wang D.L. (2015):
<a href="papers/HYCWW.jasa15.pdf">
An algorithm to increase speech intelligibility for hearing-impaired listeners in novel segments 
of the same noise type</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 138, pp. 1660-1669.
<br><br>

<LI>Williamson D.S., Wang Y., and Wang D.L. (2015): 
<A HREF="papers/WWW.jasa15.pdf">
Estimating nonnegative matrix model activations with deep neural networks to increase perceptual speech quality</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 138, pp. 1399-1407.
<br><br>

<LI>Zhao X., Wang Y., and Wang D.L. (2015):
<a href="papers/ZWW.taslp15.pdf">
Cochannel speaker identification in anechoic and reverberant conditions</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 23, pp. 1727-1736.
<br><br>

<LI>Yuan J., Wang D.L., and Cheriyadat A.M. (2015):
<a href="papers/YWC.tip15.pdf">
Factorization-based texture segmentation</a>.
<cite>IEEE Transactions on Image Processing</CITE>, 
vol. 24, pp. 3488-3497.
(<a href="https://sites.google.com/site/factorizationsegmentation/">
Description with Matlab Code</a>.)
<br><br>

<LI>Han K., Wang Y., Wang D.L., Woods W.S., Merks I., and Zhang T. (2015):
<a href="papers/HWWWMZ.taslp15.pdf">
Learning spectral mapping for speech dereverberation and denoising</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 23, pp. 982-992.
<br><br>

<LI>Narayanan A. and Wang D.L. (2015):
<a href="papers/Narayanan-Wang.taslp15.pdf">
Improving robustness of deep neural network acoustic models via speech separation and joint adaptive training</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 23, pp. 92-101.
<br><br>

<LI>Healy E.W., Yoho S.E., Wang Y., Apoux F., and Wang D.L. (2014):
<a href="papers/HYWAW.jasa14.pdf">
Speech cue transmission by an algorithm to increase consonant recognition in noise for hearing-impaired listeners</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 136, pp. 3325-3336. (<a href="papers/ConfusionMatrices.jasa14.pdf">Supplemental Confusion Matrices</a>.)
<br><br>

<LI>Han K. and Wang D.L. (2014):
<a href="papers/Han-Wang.taslp14.pdf">
Neural network based pitch tracking in very noisy speech</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 22, pp. 2158-2168.
<br><br>

<LI>Jiang Y., Wang D.L., Liu R.S., Feng Z.M. (2014):
<a href="papers/JWLF.taslp14.pdf">
Binaural classification for reverberant speech segregation using deep neural networks</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 22, pp. 2112-2121.
<br><br>

<LI>Chen J., Wang Y., and Wang D.L. (2014):
<a href="papers/CWW.taslp14.pdf">
A feature study for classification-based speech separation at low signal-to-noise ratios</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 22, pp. 1993-2002. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Wang Y., Narayanan A. and Wang D.L. (2014):
<a href="papers/WNW.taslp14.pdf">
On training targets for supervised speech separation</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 22, pp. 1849-1858
(Recipient of the 2019 <FONT2>Best Paper Award</FONT2> from the IEEE Signal Processing Society</a>).
<br><br>

<LI>Williamson D.S., Wang Y., and Wang D.L. (2014): 
<A HREF="papers/WWW.jasa14.pdf">
Reconstruction techniques for improving the perceptual quality of binary masked speech</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 136, pp. 892-902.
<br><br>

<LI>Zhao X., Wang Y., and Wang D.L. (2014):
<a href="papers/ZWW.taslp14.pdf">
Robust speaker identification in noisy and reverberant conditions</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, vol. 22, pp. 836-845.
<br><br>

<LI>Narayanan A. and Wang D.L. (2014):
<a href="papers/Narayanan-Wang.taslp14.pdf">
Investigation of speech separation as a front-end for noise robust speech recognition</a>.
<cite>IEEE/ACM Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 22, pp. 826-835.
<br><br>

<LI>Yuan J., Wang D.L., and Li R. (2014):
<a href="papers/YWL.tgrs14.pdf">
Remote sensing image segmentation by combining spectral and texture features</a>.
<cite>IEEE Transactions on Geoscience and Remote Sensing</CITE>, 
vol. 52, pp. 16-24.
<br><br>

<LI>Hartmann W., Narayanan A., Fosler-Lussier E., and Wang D.L. (2013):
<a href="papers/HNFW.taslp13.pdf">
A direct masking approach to robust ASR</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</cite>, vol. 21, pp. 1993-2005.
<br><br>

<LI>Healy E.W., Yoho S.E., Wang Y., and Wang D.L. (2013):
<a href="papers/HYWW.jasa13.pdf">
An algorithm to improve speech recognition in noise for hearing-impaired listeners</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 134, pp. 3029-3038. 
(Related <a href="http://researchnews.osu.edu/archive/cocktailparty.htm">
Press Release</a>, <a href="https://www.youtube.com/watch?v=tBNpglPHQsY">YouTube Demo</a>, and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/corpus/Healy-jasa13/YWang.html">Test Data</a>.)
<br><br>

<LI>Hu K. and Wang D.L. (2013):
<a href="http://asmp.eurasipjournals.com/content/2013/1/14">
An iterative model-based approach to cochannel speech separation</a>.
<cite>EURASIP Journal on Audio, Speech, and Music Processing</cite>, 
vol. 2013, Article ID 2013-14, 11 pages. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Narayanan A. and Wang D.L. (2013):
<a href="papers/Narayanan-Wang.jasa13.pdf">
The role of binary mask patterns in automatic speech recognition in background noise</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 133, pp. 3083-3093.
<br><br>

<LI>Wang Y. and Wang D.L. (2013):
<a href="papers/Wang-Wang.taslp13.pdf">
Towards scaling up classification-based speech separation</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 21, pp. 1381-1390.
<br><br>

<LI>Woodruff J. and Wang D.L. (2013):
<a href="papers/Woodruff-Wang.taslp13.pdf">
Binaural detection, localization, and segregation in reverberant environments based on 
joint pitch and azimuth cues</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 21, pp. 806-815.
<br><br>

<LI>Wang Y., Han K., and Wang D.L. (2013):
<a href="papers/WHW.taslp13.pdf">
Exploring monaural features for classification-based speech segregation</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 21, pp. 270-279.
<br><br>

<LI>Han K. and Wang D.L. (2013):
<a href="papers/Han-Wang.taslp13.pdf">
Towards generalizing classification based speech separation</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 21, pp. 166-175.
<br><br>

<LI>Hu K. and Wang D.L. (2013):
<a href="papers/Hu-Wang.taslp13.pdf">
An unsupervised approach to cochannel speech separation</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 21, pp. 120-129. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Han K. and Wang D.L. (2012):
<a href="papers/Han-Wang.jasa12.pdf">
A classification based approach to speech segregation</a>.
<cite>Journal of the Acoustical Society of America</CITE>, vol. 132, pp. 3475-3483.
<br><br>

<LI>Narayanan A. and Wang D.L. (2012):
<a href="papers/Narayanan-Wang.taslp12.pdf">
A CASA based system for long-term SNR estimation</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</cite>,
vol. 20, pp. 2518-2527. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Zhao X., Shao Y., and Wang D.L. (2012):
<a href="papers/ZSW.taslp12.pdf">
CASA-based robust speaker identification</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 20, pp. 1608-1616. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Woodruff J. and Wang D.L. (2012):
<a href="papers/Woodruff-Wang.taslp12.pdf">
Binaural localization of multiple sources in reverberant and noisy environments</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 20, pp. 1503-1512.
<br><br>

<LI>Hsu C.-L., Wang D.L., Jang J.-S.R., and Hu K. (2012):
<a href="papers/HWJH.taslp12.pdf">
A tandem algorithm for singing pitch extraction and voice separation from
music accompaniment</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 20, pp. 1482-1491.
<br><br>

<LI>Yuan J., Wang D.L., and Li R. (2012):
<a href="papers/YWL.prl12.pdf">
Image segmentation using local spectral histograms and linear regression</a>.
<cite>Pattern Recognition Letters</CITE>, 
vol. 33, pp. 615-622.
<br><br>

<LI>Yuan J., Wang D.L., Wu B., Yan L., and Li R. (2011):
<a href="papers/YWWYL.tgrs11.pdf">
LEGION-based automatic road extraction from satellite imagery</a>.
<cite>IEEE Transactions on Geoscience and Remote Sensing</CITE>, 
vol. 49, pp. 4528-4538.
<br><br>

<LI>Jin Z. and Wang D.L. (2011):
<a href="papers/Jin-Wang.taslp11_2.pdf">
Reverberant speech segregation based on multipitch tracking and classification</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 19, pp. 2328-2337. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Hu K. and Wang D.L. (2011):
<a href="papers/Hu-Wang.taslp11.pdf">
Unvoiced speech segregation from nonspeech interference via CASA and spectral subtraction</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 19, pp. 1600-1609. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Jin Z. and Wang D.L. (2011):
<a href="papers/Jin-Wang.taslp11.pdf">
HMM-based multipitch tracking for noisy and reverberant speech</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 19, pp. 1091-1102. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Jan T., Wang W., Wang D.L. (2011):
<A HREF="papers/JWW.spcomm11.pdf">
A multistage approach to blind separation of convolutive speech mixtures</a>.
<cite>Speech Communication</cite>, vol. 53, pp. 524-539.
<br><br>

<LI>Quiles M.G., Wang D.L., Zhao L., Romero R.A.F., and Huang D.-S. (2011):
<a href="papers/QWZRH.nn11.pdf">
Selecting salient objects in real scenes: An oscillatory correlation model</a>.
<cite>Neural Networks</CITE>, 
vol. 24, pp. 54-64.
<br><br>

<LI>Hu G. and Wang D.L. (2010):
<a href="papers/Hu-Wang.taslp10.pdf">
A tandem algorithm for pitch estimation and voiced speech segregation</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 18, pp. 2067-2079. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/demo.html">
Sound Demo</a> and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Narayanan A. and Wang D.L. (2010):
<a href="papers/Narayanan-Wang.jasa10.pdf">
Robust speech recognition from binary masks</a>.
<cite>Journal of the Acoustical Society of America Express Letters</cite>,
vol. 128, pp. EL217-222.
<br><br>

<LI>Woodruff J. and Wang D.L. (2010):
<a href="papers/Woodruff-Wang.taslp10.pdf">
Sequential organization of speech in reverberant environments by integrating 
monaural grouping and binaural localization</a>.
<cite>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 18, pp. 1856-1866.
<br><br>

<LI>Srinivasan S. and Wang D.L. (2010):
<A HREF="papers/Sriniv-Wang.spcomm10.pdf">
Robust speech recognition by integrating speech separation and hypothesis testing</a>.
<cite>Speech Communication</cite>, vol. 52, pp. 72-81.
<br><br>

<LI>Shao Y., Srinivasan S., Jin Z., and Wang D.L. (2010):
<a href="papers/SSJW.csl10.pdf">
A computational auditory scene analysis system for speech segregation and 
robust speech recognition</a>.
<cite>Computer Speech and Language</cite>, vol. 24, pp. 77-93.
<br><br>

<LI>Kjems U., Boldt J.B., Pedersen M.S., Lunner T., and Wang D.L. (2009):
<A HREF="papers/KBPLW.jasa09.pdf">
Role of mask pattern in intelligibility of ideal binary-masked noisy speech</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 126, pp. 1415-1426.
<br><br>

<LI>Li Y., Woodruff J., and Wang D.L. (2009):
<a href="papers/LWW.taslp09.pdf">
Monaural musical sound separation based on pitch and common amplitude modulation</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 17, pp. 1361-1371. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/demo.html">
Sound Demo</a> and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Li Y. and Wang D.L. (2009):
<a href="http://asmp.eurasipjournals.com/content/2009/1/130567">
Musical sound separation based on binary time-frequency masking</a>.
<cite>EURASIP Journal on Audio, Speech, and Music Processing</cite>, 
vol. 2009, Article ID 130567, 10 pages.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/demo.html">
Sound Demo</a>.)
<br><br>

<LI>Shao Y. and Wang D.L. (2009):
<a href="papers/Shao-Wang.spcomm09.pdf">
Sequential organization of speech in computational auditory scene analysis</a>.
<cite>Speech Communication</cite>, vol. 51, pp. 657-667.
<br><br>

<LI>Brungart D.S., Chang P.S., Simpson B.D., and Wang D.L. (2009):
<a href="papers/BCSW.jasa09.pdf">
Multitalker speech perception with ideal time-frequency segregation: Effects of voice characteristics and number of talkers</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 125,  pp. 4006-4022.
<br><br>

<LI>Wang D.L., Kjems U., Pedersen M.S., Boldt J.B., and Lunner T. (2009):
<A HREF="papers/WKPBL.jasa09.pdf">
Speech intelligibility in background noise with ideal binary time-frequency masking</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 125, pp. 2336-2347.
<br><br>


<LI>Jin Z. and Wang D.L. (2009):
<a href="papers/Jin-Wang.taslp09.pdf">
A supervised learning approach to monaural segregation of reverberant speech</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 17, pp. 625-638.
<br><br>

<LI>Li Y. and Wang D.L. (2009):
<a href="papers/Li-Wang.spcomm09.pdf">
On the optimality of ideal binary time-frequency masks</a>.
<cite>Speech Communication</cite>, vol. 51, pp. 230-239.
<br><br>

<LI>Wang D.L. (2008):
<A HREF="papers/Wang.tia08.pdf">
Time-frequency masking for speech separation and its potential for hearing aid design</a>.
<cite>Trends in Amplification</cite>, vol. 12, pp. 332-353.
<br><br>

<LI>Srinivasan S. and Wang D.L. (2008):
<A HREF="papers/Sriniv-Wang.jasa08.pdf">
A model for multitalker speech perception</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 124, pp. 3213-3224.
<br><br>

<LI>Wang D.L., Kjems U., Pedersen M.S., Boldt J.B., and Lunner T. (2008):
<A HREF="papers/WKPBL.jasa08.pdf">
Speech perception of noise with binary gains</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 124, pp. 2303-2307.
<br><br>

<LI>Hu G. and Wang D.L. (2008):
<a href="papers/Hu-Wang.jasa08.pdf">
Segregation of unvoiced speech from nonspeech interference</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 124, pp. 1306-1319.
<br><br>

<LI>Roman N. and Wang D.L. (2008):
<a href="papers/Roman-Wang.taslp08.pdf">
Binaural tracking of multiple moving sources</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, 
vol. 16, pp. 728-739.
<br><br>

<LI> Wang D.L. and Chang P.S. (2008):
<a href="papers/Wang-Chang.cody08.pdf">
An oscillatory correlation model of auditory streaming</a>.
<CITE>Cognitive Neurodynamics</CITE>, vol. 2, pp. 7-19.
<br><br>

<LI>Pedersen M.S., Wang D.L., Larsen J., and Kjems U. (2008):
<A HREF="papers/PWLK.tnn08.pdf">
Two-microphone separation of speech mixtures</a>.
<cite>IEEE Transactions on Neural Networks</cite>, vol. 19, pp. 475-492.
(Related <a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=4400">Sound Demo</a> and <a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=4399">Source Code</a>.)
<br><br>

<LI>Srinivasan S. and Wang D.L. (2007):
<a href="papers/Sriniv-Wang.taslp07.pdf">
Transforming binary uncertainties for robust
speech recognition</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 15, pp. 2130-2140.
<br><br>

<LI>Li Y. and Wang D.L. (2007):
<a href="papers/Li-Wang.taslp07.pdf">
Separation of singing voice from music accompaniment for monaural 
recordings</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 15, pp. 1475-1487. (Related <a href="pnl/demo.html">
Sound Demo</a> and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Hu G. and Wang D.L. (2007): 
<a href="papers/Hu-Wang.taslp07.pdf">
Auditory segmentation based on onset and offset analysis</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 15, pp. 396-405. (Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Roman N., Srinivasan S., and Wang D.L. (2006):
<a href="papers/RSW.jasa06.pdf">
Binaural segregation in multisource reverberant environments</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 120, pp. 4040-4051.
<br><br>

<LI>Brungart D.S., Chang P.S., Simpson B.D., and Wang D.L. (2006):
<a href="papers/BCSW.jasa06.pdf">
Isolating the energetic component of speech-on-speech masking with ideal time-frequency segregation</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 120,  pp. 4007-4018.
<br><br>

<LI>Srinivasan S., Roman N., and Wang D.L. (2006):
<a href="papers/SRW.spcomm06.pdf">
Binary and ratio time-frequency masks for robust speech recognition</a>.
<cite>Speech Communication</cite>, vol. 48, pp. 1486-1501.
<br><br>

<LI>Liu X. and Wang D.L. (2006): 
<a href="papers/Liu-Wang.tip06.pdf">
Image and texture segmentation using local spectral histograms</a>.
<CITE>IEEE Transactions on Image Processing</CITE>, vol. 15, pp. 3066-3077.
<br><br>

<LI> Roman N. and Wang D.L. (2006): 
<a href="papers/Roman-Wang.jasa06.pdf">
Pitch-based monaural segregation of reverberant speech</a>.
<CITE>Journal of the Acoustical Society of America</CITE>, vol. 120, pp. 
458-469.
<br><br>

<LI>Wu M. and Wang D.L. (2006): 
<a href="papers/Wu-Wang.taslp06.pdf">
A two-stage algorithm for one-microphone reverberant speech enhancement</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE>, vol. 14, pp. 774-784.
(Related <a href="https://pnlwang.github.io/pnl/demo/WuReverb.html">Sound Demo</a> and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Wu M. and Wang D.L. (2006): 
<a href="papers/Wu-Wang.acustica06.pdf">
A pitch-based method for the estimation of short reverberation time</a>.
<CITE>Acta Acustica united with Acustica</CITE>, vol. 92, pp. 337-339.
<br><br>

<LI>Shao Y. and Wang D.L. (2006):
<a href="papers/Shao-Wang.taslp06.pdf">
Model-based sequential organization in cochannel speech</a>.
<CITE>IEEE Transactions on Audio, Speech, and Language Processing</CITE> 
(formerly <CITE>IEEE Transactions on Speech and Audio Processing</CITE>), 
vol. 14, pp. 289-298.
<br><br>

<LI>Wang D.L. (2005):
<a href="papers/Wang.tnn05.pdf">
The time dimension for scene analysis</a>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 16, pp. 1401-1426 
(Recipient of the 2007 <FONT2>Outstanding Paper Award</FONT2> from the IEEE Computational Intelligence Society</a>).
<br><br>

<LI>Wang D.L., Kristjansson A., and Nakayama K. (2005): 
<A HREF="papers/WKN.pandp05.pdf">
Efficient visual search without top-down or bottom-up guidance</a>. 
<cite>Perception & Psychophysics</cite>, vol. 67, pp. 239-253. 
<br><br>

<LI>Srinivasan S. and Wang D.L. (2005):
<a href="papers/Sriniv-Wang.spcomm05.pdf">
A schema-based model for phonemic restoration</a>.
<cite>Speech Communication</cite>, vol. 45, pp. 63-87.
<br><br>

<LI>Palomaki K.J., Brown G.J., and Wang D.L. (2004): 
<A HREF="papers/PBW.spcomm04.pdf">
A binaural processor for missing data speech recognition in the presence
of noise and small-room reverberation</A>.
<CITE>Speech Communication</CITE>, vol. 43, pp. 361-378. 
<br><br>

<LI>Hu G. and Wang D.L. (2004):
<a href="papers/Hu-Wang.tnn04.pdf">
Monaural speech segregation based on pitch tracking and amplitude
modulation</a>. <cite>IEEE Transactions on Neural Networks</cite>,
vol. 15, pp. 1135-1150.
(Related <a href="pnl/demo/HuVoiced.html">
Sound Demo</a> and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Campbell S.R., Wang D.L., and Jayaprakash C. (2004): 
<A HREF="papers/CWJ.tnn04.pdf">
Synchronization rates in classes of relaxation oscillators</A>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 15, 
pp. 1027-1038. 
<br><br>

<LI>Wang D.L., Freeman W.J., Kozma R., Lozowski A., and Minai A. (2004): 
<A HREF="papers/WFKLM.tnn04.pdf">
Guest Editorial for Special Issue on Temporal Coding for Neural
Information Processing</A>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 15, 
pp. 953-956. 
<br><br>

<LI>Roman N., Wang D.L., Brown G.J. (2003):
<a href="papers/RWB.jasa03.pdf">
Speech segregation based on sound localization</a>.
<cite>Journal of the Acoustical Society of America</cite>, vol. 114, Pt. 1,
pp. 2236-2252.
(Related <a href="pnl/demo/RomanBinaural.html">
Sound Demo</a> and <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Liu X., Srivastava A., and Wang D.L. (2003): 
<A HREF="papers/LSW.nn03.pdf">
Intrinsic generalization analysis of low dimensional representations</A>.
<CITE>Neural Networks</CITE>, vol. 16, pp. 537-545. 
<br><br>

<LI>Liu X. and Wang D.L. (2003): 
<A HREF="papers/Liu-Wang.tip03.pdf">
Texture classification using spectral histograms</A>.
<CITE>IEEE Transactions on Image Processing</CITE>, vol. 12, pp. 661-670. 
<br><br>

<LI>Wu M., Wang D.L., and Brown G.J. (2003): 
<a href="papers/WWB.tsap03.pdf">
A multipitch tracking algorithm for noisy speech</a>.
<CITE>IEEE Transactions on Speech and Audio Processing</CITE>, vol. 11, pp. 229-241.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI> Cesmeli E., Lindsey D.T., and Wang D.L. (2002): 
<a href="papers/CLW.p&p02.pdf">
An oscillatory correlation model of visual motion analysis</a>.
<CITE>Perception & Psychophysics</CITE>, vol. 64, 1191-1217. 
<br><br>

<LI>Liu X. and Wang D.L. (2002): 
<A HREF="papers/Liu-Wang.vr02.pdf">
A spectral histogram model for texton modeling and texture 
discrimination</A>.
<CITE>Vision Research</CITE>, vol. 42, 2617-2634.
<br><br>

<LI>Kristjansson A., Wang D.L., and Nakayama K. (2002): 
<A HREF="papers/KWN.cog02.pdf">
The role of priming in conjunctive visual search</A>.
<CITE>Cognition</CITE>, vol. 85, 37-52. 
<br><br>

<LI>Chen K. and Wang D.L. (2002): 
<A HREF="papers/Chen-Wang.nn02.pdf">
A dynamically coupled neural oscillator network for image segmentation</A>.
<CITE>Neural Networks</CITE>, vol. 15, 423-439. 
<br><br>

<LI>Wang D.L. and Liu X. (2002): 
<A HREF="papers/Wang-Liu.tsmc02.pdf">
Scene analysis by integrating primitive segmentation and associative memory</A>.
<CITE>IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics</CITE>, vol. 32, 254-268. 
<br><br>

<LI>Chen K. and Wang D.L. (2001): 
<A HREF="papers/Chen-Wang.tnn01.pdf">
Perceiving geometric patterns: from spirals to inside/outside relations</A>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 12, 1084-1102. 
<br><br>

<LI>Wang D.L. (September 2001): 
<A HREF="papers/Wang.aim01.pdf">
Book Review: <em>Unsupervised Learning - Foundations of Neural 
Computation</em></A>. Edited by G. Hinton and T.J. Sejnowski, MIT Press, 1999.
<CITE>AI Magazine</CITE>, vol. 22, 101-102.
<br><br>

<LI>Fox J.J., Jayaprakash C., Wang D.L., and Campbell S.R. (2001): 
<A HREF="papers/FJWC.nc01.pdf">
Synchronization in relaxation oscillator networks with conduction 
delays</A>.
<CITE>Neural Computation</CITE>, vol. 13, 1003-1021.
<br><br>

<LI>Cesmeli E. and Wang D.L. (2001):
<A HREF="papers/Cesmeli-Wang.tnn01.pdf">
Texture segmentation using Gaussian-Markov random fields and
neural oscillator networks</A>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 12, 394-404.
<br><br>

<LI>Liu X., Chen K., and Wang D.L. (2001):
<A HREF="papers/LCW.tgrs01.pdf">
Extraction of hydrographic regions
from remote sensing images using an oscillator network with weight
adaptation</A>.
<CITE>IEEE Transactions on GeoScience and Remote Sensing</cite>,
vol. 39, 207-211. For a more extensive version see
<A HREF="file://ftp.cse.ohio-state.edu/pub/tech-report/1999/TR12.ps.gz">
Technical Report OSU-CISRC-4/99-TR12</A>, 1999,
Department of Computer and Information Science,
The Ohio State University, Columbus, Ohio, USA.
<br><br>

<LI>van der Kouwe A.J.W., Wang D.L., and Brown G.J. (2001):
<A HREF="papers/KWB.tsap01.pdf">
A comparison of auditory
and blind separation techniques for speech segregation</A>.
<CITE>IEEE Transactions on Speech and Audio Processing</CITE>, vol. 9, 189-195.
<br><br>

<LI>Chen K., Wang D.L., and Liu X. (2000): 
<A HREF="papers/CWL.tnn00.pdf">Weight adaptation 
and oscillatory correlation for image segmentation</A>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 11, 1106-1123.
<br><br>

<LI>Cesmeli E. and Wang D.L. (2000): 
<A HREF="papers/Cesmeli-Wang.tnn00.pdf">Motion 
segmentation based on motion/brightness
integration and oscillatory correlation</A>. <CITE>IEEE Transactions 
on Neural Networks</CITE>, vol. 11, 935-947.
<br><br>

<LI>Wang D.L. (2000): 
<A HREF="papers/Wang00.pdf">On connectedness: a 
solution based on oscillatory correlation</A>. 
<CITE>Neural Computation</CITE>, vol. 12, 131-139.
<br><br>

<LI>Liu X., Wang D.L., and Ramirez J.R. (2000): 
<A HREF="papers/LWR.pr00.pdf">
Boundary detection by contextual nonlinear smoothing</A>.
<CITE>Pattern Recognition</CITE>, vol. 33, 263-280.
<br><br>

<LI>Campbell S.R., Wang D.L., and Jayaprakash C. (1999): 
<A HREF="papers/CWJ99.pdf">Synchrony and desynchrony in 
integrate-and-fire oscillators</a>. <cite>Neural Computation</cite>, 
vol. 11, 1595-1619.
<br><br>

<LI>Wang D.L. and Brown G.J. (1999): 
<A HREF="papers/Wang-Brown.tnn99.pdf">
Separation of speech from interfering sounds based on oscillatory 
correlation</a>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 10, 684-697.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Liu X. and Wang D.L. (1999):
<A HREF="papers/Liu-Wang.tnn99.pdf">
Range image segmentation using a LEGION network</A>.
<CITE> IEEE Transactions on Neural Networks</CITE>, vol. 10, 564-573.
<br><br>

<LI>Wang D.L. (1999): 
<A HREF="papers/Wang.nn99.pdf">
Object selection based on oscillatory correlation</a>.
<CITE>Neural Networks</CITE>, vol. 12, 579-592.
<br><br>

<LI>Shareef N., Wang D.L., and Yagel R. (1999): 
<A HREF="papers/SWY.tmi99.pdf">Segmentation of medical images 
using LEGION</A>. <CITE>IEEE Transactions on Medical Imaging</CITE>, 
vol. 18, 74-91. 
<A HREF="https://web.cse.ohio-state.edu/~shareef/OSUTR26/journal-1.html">Click
here for an HTML version, slightly different from the printed version</A>.
<br><br>

<LI>Linsay P.S. and Wang D.L. (1998): 
<A HREF="papers/Linsay-Wang.tnn98.pdf">
Fast numerical integration of relaxation oscillator networks based on 
singular limit solutions</a>.
<CITE> IEEE Transactions on Neural Networks</CITE>, vol. 9, 523-532.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Campbell S.R. and Wang D.L. (1998): 
<A HREF="papers/Campbell-Wang98.pdf">Relaxation oscillators with time 
delay coupling</A>.
<CITE>Physica D</CITE>, vol. 111, 151-178.
<br><br>

<LI>Wang D.L. (1997): 
<A HREF="papers/Wang97.pdf">
On the computational basis of synchronized codes</a>. 
<cite>Behavioral and Brain Sciences</cite>, vol. 20, 700-701.
<br><br>

<LI>Wang D.L. and Terman D. (1997): 
<A HREF="papers/Wang-Terman97.pdf">
Image segmentation based on oscillatory correlation</a>. 
<cite>Neural Computation</cite>, vol. 9, 805-836 
(For errata see Neural Computation, vol. 9, 1623-1626, 1997). Also, for
an earlier but extended version with detailed analysis see
<A HREF="papers/Cogsci-report19.pdf">
Image segmentation based on oscillatory correlation</a>. 
<cite>Technical Report</cite> 19, Center for Cognitive Science, 
The Ohio State University, Columbus, Ohio, USA.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Brown G.J. and Wang D.L. (1997): 
<A HREF="papers/Brown-Wang97.pdf">
Modelling the perceptual segregation of 
double vowels with a network of neural oscillators</A>.
<CITE>Neural Networks</CITE>, vol. 10, 1547-1558.
<br><br>

<LI>Wang D.L. and Yuwono B. (1996):
<A HREF="papers/Wang-Yuwono.tnn96.pdf"> 
Incremental learning of complex temporal patterns</a>.
<CITE>IEEE Transactions on Neural Networks</CITE>, vol 7, 1465-1481.
<br><br>

<LI>Wang D.L. (1996): 
<A HREF="papers/Wang96.pdf">
Primitive auditory segregation based on oscillatory correlation</a>.
<CITE>Cognitive Science</CITE>, vol. 20, 409-456.
<br><br>

<LI>Campbell S.R. and Wang D.L. (1996): 
<A HREF="papers/Campbell-Wang.tnn96.pdf">
Synchronization and desynchronization in a network of locally coupled 
Wilson-Cowan oscillators</a>.
 <CITE> IEEE Transactions on Neural Networks</CITE>, vol. 7(3), 541-554.
<br><br>

<LI>Wang D.L., Liu, X.M., and Ahalt, S.C. (1996): 
<A HREF="papers/WLA96.pdf">
On temporal generalization of simple recurrent networks</a>.
<CITE>Neural Networks</CITE>, vol. 9, 1099-1118.
<br><br>

<LI>Wang D.L. and Yuwono B. (1995): 
<A HREF="papers/Wang-Yuwono.smc95.pdf">
Anticipation-based temporal pattern generation</a>. 
<CITE>IEEE Transactions on Systems, Man, and Cybernetics</CITE>,
vol. 25, 615-628.
<br><br>

<LI>Wang D.L. (1995): 
<A HREF="papers/Wang.tnn95.pdf">
Emergent synchrony in locally coupled neural oscillators</a>.
<CITE> IEEE Transactions on Neural Networks</CITE>, vol. 6, 941-948.
<br><br>

<LI>Terman D. and Wang D.L. (1995): 
<A HREF="papers/Terman-Wang95.pdf">
Global competition and local cooperation 
in a network of neural oscillators</a>. 
<CITE> Physica D</CITE>, vol. 81, 148-176.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Wang D.L. and Terman D. (1995): 
<A HREF="papers/Wang-Terman.tnn95.pdf">
Locally excitatory globally inhibitory oscillator networks</a>. 
<CITE>IEEE Transactions on Neural Networks</CITE>, vol. 6(1), 283-286.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Wang D.L. (1994):
<A HREF="papers/Wang.jcn94.pdf">
 Modeling neural mechanisms of vertebrate habituation: 
        Locus specificity and pattern discrimination</a>.
<CITE>Journal of Computational Neuroscience</CITE>, vol. 1(4), 285-299.
<br><br>

<LI>Wang D.L. (1993): 
<A HREF="papers/Wang.ab93.pdf">
A neural model of synaptic plasticity underlying 
short-term and long-term habituation</a>. <CITE>Adaptive Behavior</CITE>,
vol. 2, 111-129.
<br><br>

<LI>Wang D.L. and Arbib M.A. (1993): 
<A HREF="papers/Wang-Arbib.smc93.pdf">
Timing and chunking in processing temporal order</a>.  
<CITE>IEEE Transactions on Systems, Man, and 
Cybernetics</CITE>, vol. 23, 993-1009.
<br><br>

<LI>Wang D.L. (August 1993): 
<A HREF="papers/Wang.expert93.pdf">
Pattern recognition: Neural networks in perspective</A>. 
<CITE>IEEE Expert</CITE>, vol. 8, 52-60.
<br><br>

<LI>Wang D.L. and Arbib M.A. (1992): 
<A HREF="papers/Wang-Arbib.biocyb92.pdf">
The dishabituation hierarchy in toads: the role of the primordial hippocampus</a>.
<CITE> Biological Cybernetics</CITE>, vol. 67, 535-544.
<br><br>

<LI>Wang D.L. and Ewert J.-P. (1992):
<A HREF="papers/Wang-Ewert.jcp02.pdf">
Configurational pattern discrimination responsible for dishabituation in common toads 
Bufo bufo (L.): behavioral tests of the predictions of a neural model</a>. 
<CITE>Journal of Comparative Physiology</CITE> A, vol. 170, 317-325.
<br><br>

<LI>Wang D.L. and Arbib M.A.(1991): 
<A HREF="papers/Wang-Arbib.biocyb91.pdf">
How does the toad's visual system discriminate different worm-like stimuli</a>? 
<CITE> Biological Cybernetics</CITE>, vol. 64, 251-261.
<br><br>

<LI>Wang D.L., Buhmann J., and von der Malsburg C. (1990): 
<A HREF="papers/WBM.nc90.pdf">
Pattern segmentation in associative memory</a>. 
<CITE>Neural Computation</CITE>, 
vol. 2, 94-106.  Reprinted as a book chapter in 1991.
<br><br>

<LI>Wang D.L. and Hsu C.C. (1990): 
<A HREF="papers/Wang-Hsu.sim90.pdf">
SLONN: A simulation language for modeling of neural networks</a>.  
<CITE>Simulation</CITE>, vol. 55, 69-83.
<br><br>

<LI>Wang D.L. and Arbib M.A. (1990): 
<A HREF="papers/Wang-Arbib.pieee90.pdf">
Complex temporal sequence learning 
based on short-term memory</a>. 
<CITE>Proceedings of the IEEE</CITE>, vol. 78, 1536-1543.
<br><br>

<LI>Wang D.L. and Hsu C.C. (1988): 
<A HREF="papers/Wang-Hsu.aas88.pdf">
A neuron model for computer simulation of neural networks</a>. 
<CITE>Acta Automatica Sinica</CITE> (both in Chinese and in English), vol. 14, 424-430.
<br><br>

<LI>Hsu C.C. and Wang D.L. (1988):
<A HREF="papers/Wang-Hsu.jcomp88.pdf">
SLONN: A simulation language for neural networks and its implementation</a>. 
<CITE>Journal of Computers</CITE> (in Chinese), vol. 11, 741-749.
<br><br>

<LI>Wang D.L. (1986):
<A HREF="papers/Wang.cogsci86.pdf">
A neuron model based on information processing of the nervous system</a>. 
<CITE>Cognitive Science</CITE> (in Chinese), January 
1986, 81-88.
<br>

</UL>
<H5><a TARGET=_self HREF="pubs_year.html#top">Top of Page</a></H5>



<!-- ########################## -->

<a Name = "chapter"></a>

<H3>Book Chapters</H3>

<UL>

<LI>Narayanan A. and Wang D.L. (2013):
<A HREF="papers/Narayanan-Wang13.pdf">
Computational auditory scene analysis and automatic speech recognition</A>. In Virtanen T., Singh R., and Raj B. (ed.),
<CITE>Techniques for Noise Robustness in Automatic Speech Recognition</CITE>, Wiley & Sons, pp. 433-462.
<br><br>

<LI>Wang D.L. (2007):
<A HREF="papers/Wang07.pdf">
Computational scene analysis</A>. In Duch W. and Mandziuk J. (ed.),
<CITE>Challenges for Computational Intelligence</CITE>, Springer, 
Berlin, pp. 163-191.
<br><br>

<LI>Hu G. and Wang D.L. (2006):
<A HREF="papers/Hu-Wang06.pdf">
An auditory scene analysis approach to monaural speech segregation</A>. In Hansler E. and Schmidt G. (ed.),
<CITE>Topics in Acoustic Echo and Noise Control</CITE>, Springer, 
Heidelberg, pp. 485-515.
<br><br>

<LI>Brown G.J. and Wang D.L. (2006):
Timing is of the essence: Neural 
oscillator models of auditory grouping. In Greenberg S. and Ainsworth W. (ed.),
<CITE>Listening to Speech: An Auditory Perspective</CITE>, Lawrence Erlbaum, 
Mahwah NJ.
<br><br>

<LI>Brown G.J. and Wang D.L. (2005):
<A HREF="papers/Brown-Wang05.pdf">
Separation of speech by computational auditory scene analysis</A>. 
In Benesty J., Makino S., and Chen J. (ed.),
<CITE>Speech Enhancement</CITE>, Springer, New York, pp. 371-402.
<br><br>

<LI>Wang D.L. (2005): 
<A HREF="papers/Wang05.pdf">
On ideal binary mask as the computational goal of auditory scene analysis</A>. In Divenyi P. (ed.),
<CITE>Speech Separation by Humans and Machines</CITE>, pp. 181-197, Kluwer Academic, Norwell MA.
<br><br>

<LI>Wang D.L. (2003): 
<A HREF="papers/Wang1.hbtnn03.pdf">
Temporal pattern processing</a>. In: Arbib M.A. (ed.), 
<CITE>The Handbook of Brain Theory and Neural Networks, 2nd Ed.</CITE>, 
pp. 1163-1167, MIT Press, Cambridge MA.
<br><br>

<LI>Wang D.L. (2003): 
<A HREF="papers/Wang2.hbtnn03.pdf">
Visual scene segmentation</a>. In: Arbib M.A. (ed.), 
<CITE>The Handbook of Brain Theory and Neural Networks, 2nd Ed.</CITE>, 
pp. 1215-1219, MIT Press, Cambridge MA.
<br><br>

<LI>Wang D.L. (2000): 
<A HREF="papers/WangBook00.pdf">
Anticipation model for sequential learning of complex sequences</a>. 
In Run R. and Giles C.L. (eds.), 
<cite>Sequence Learning</cite>, LNAI 1828, pp. 53-79,
Springer-Verlag, Berlin Heidelberg.
<br><br>

<LI>Wang D.L. (1999): 
<A HREF="papers/Wang99.pdf">
Relaxation oscillators and networks</a>. In Webster J. (ed.), 
<cite>Wiley Encyclopedia of Electrical and Electronics Engineering</cite>, 
vol. 18, pp. 396-405, Wiley & Sons.
<br><br>

<LI>Wang D.L. (1998):
 Stream segregation based on oscillatory correlation. In Rosenthal D. and 
Okuno H.G. (eds.), <CITE>Computational Auditory Scene Analysis</CITE>, 
pp. 71-86, Lawrence Erlbaum, Mahwah NJ.
<br><br>

<LI>Wang D.L. (1996): 
Synchronous oscillations based on lateral connections. 
In Sirosh J., Miikkulainen R., and Choe Y. (eds.), 
<CITE><A HREF="http://www.cs.utexas.edu/users/nn/web-pubs/htmlbook96/">
Lateral Connections in the Cortex: Structure and Function</A></CITE>.
<br><br>

<LI>Wang D.L. (1995): 
An oscillatory correlation theory of temporal  pattern segmentation. 
In Covey E., Hawkins H., and Port R.F. (eds), <CITE>Neural Representation of
 Temporal Patterns</CITE>, pp. 53-75, Plenum, New York.
<br><br>

<LI>Wang D.L. (1995): 
Temporal pattern processing. In: Arbib M.A. (ed.), 
        <CITE>The Handbook of Brain Theory and Neural Networks</CITE>, 
pp. 967-971, MIT Press, Cambridge MA.
<br><br>

<LI>Wang D.L. (1995): 
Habituation. In: Arbib M.A. (ed.), <CITE>The 
        Handbook of Brain Theory and Neural Networks</CITE>, pp. 441-444, 
        MIT Press.
<br><br>

<LI>Arbib M.A. and Wang D.L. (1991): 
Computational models of visual pattern 
        discrimination in common toads. In: Ewert J.-P. and Werner H. (eds), 
        <CITE>Models of Brain Function and Artificial Neuronal Nets</CITE>, 
pp. 67-97, GhK University Edition, Kassel, Germany.
<br><br>

<LI>Wang D.L., Arbib M.A., and Ewert J.-P. (1991): 
Dishabituation 
hierarchies for visual pattern discrimination in toads: A dialog between 
modeling and experimentation. In: Arbib M.A. and Ewert J.-P. (eds),
 <CITE>Visual Structures and Integrated Functions</CITE>, Research Notes in 
Neural Computing, pp. 427-441, Springer-Verlag, Berlin. 
<br><br>

<LI>Wang D.L., Buhmann J., and von der Malsburg C. (1991):
Pattern segmentation in associative memory. In: David J.L. and Eichenbaum H. 
        (eds), <CITE>Olfaction: A Model System for Computational 
Neuroscience</CITE>, pp. 213-224, MIT Press, Cambridge, MA.  Reprint of 
the 1990 <em>Neural Computation</em> article.
<br><br>

<LI>Wang D.L. (1986): 
Computer simulation. In: Mao Y.S. (ed), <CITE>Handbook
for Modern Engineers</CITE> (in Chinese), pp. 615-617, Beijing Press, 
Beijing, China.  This book won the 1986 National Award of Excellent and 
Best-selling Book of Science and Technology.
<br>

</UL>
<H5><a TARGET=_self HREF="pubs_year.html#top">Top of Page</a></H5>


<!-- ################################## -->

<a Name = "paper"></a>

<H3>Conference Papers</H3>

<UL>

<em>The following abbreviations are used</em>:<br>
<br>
CNS: <em>Annual Meeting of Computation and Neural Systems</em><br>
ICASSP: <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em><br>
ICNN: <em>IEEE International Conference on Neural Networks</em><br>
ICSLP: <em>Internation Conference on Spoken Language Processing</em><br>
IJCNN: <em>International Joint Conference on Neural Networks</em><br>
ISMIR: <em>International Conference on Music Information Retrieval</em><br>
NIPS: <em>Annual Conference on Neural Information Processing Systems</em><br>
<br>

<LI>Pandey A., Xu B., Kumar A., Donley J., Calamia P., and Wang D.L. (2022b): 
<A HREF="papers/PXKDCW.icassp22b.pdf">
Multichannel speech enhancement without beamforming</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 6502-6506.
<br><br>

<LI>Pandey A., Xu B., Kumar A., Donley J., Calamia P., and Wang D.L. (2022a): 
<A HREF="papers/PXKDCW.icassp22a.pdf">
TPARN: Triple-path attentive recurrent network for time-domain multichannel speech enhancement</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 6497-6501.
<br><br>

<LI>Taherian H., Tan K., and Wang D.L. (2022): 
<A HREF="papers/TTW.icassp22.pdf">
Location-based training for multi-channel talker-independent speaker separation</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 696-700.
<br><br>

<LI>Wang H. and Wang D.L. (2022): 
<A HREF="papers/WangH-Wang.icassp22.pdf">
Cross-domain speech enhancement with a neural cascade architecture</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 7862-7866.
<br><br>

<LI>Wang H., Zhang X., and Wang D.L. (2022): 
<A HREF="papers/WZW.icassp22.pdf">
Attention-based fusion for bone-conducted and air-conducted speech enhancement in the complex domain</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 7757-7761.
<br><br>

<LI>Wang H., Qian Y., Wang X., Wang Y., Wang C., Liu S., Yoshioka T., Li J., and Wang D.L. (2022): 
<A HREF="papers/WangEtAl.icassp22.pdf">
Improving noise robustness of contrastive speech representation learning with speech reconstruction</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 6062-6066.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2022): 
<A HREF="papers/WangZ-Wang.icassp22.pdf">
Localization based sequential grouping for continuous speech separation</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 281-285.
<br><br>

<LI>Yu F. et al. (2022): 
<A HREF="papers/YuEtAl.icassp22.pdf">
Summary on the ICASSP 2022 multi-channel multi-party meeting transcription grand challenge</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 9156-9160.
<br><br>

<LI>Zhang H. and Wang D.L. (2022): 
<A HREF="papers/Zhang-Wang.icassp22.pdf">
Neural cascade architecture for joint acoustic echo and noise suppression</a>.
<cite>Proceedings of ICASSP-22</cite>, pp. 671-675.
<br><br>

<LI>Zhang H. and Wang D.L. (2021b): 
<A HREF="papers/Zhang-Wang.interspeech21b.pdf">
A deep learning approach to multi-channel and multi-microphone acoustic echo cancellation</a>.
<cite>Proceedings of INTERSPEECH-21</cite>, pp. 1139-1143.
<br><br>

<LI>Zhang H. and Wang D.L. (2021a): 
<A HREF="papers/Zhang-Wang.interspeech21a.pdf">
A deep learning method to multi-channel active noise control</a>.
<cite>Proceedings of INTERSPEECH-21</cite>, pp. 681-685.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2021): 
<A HREF="papers/Wang-Wang.icassp21.pdf">
Count and separate: incorporating speaker counting for continuous speaker separation</a>.
<cite>Proceedings of ICASSP-21</cite>, pp. 11-15.
<br><br>

<LI>Zhang Y., Liu Y., and Wang D.L. (2021): 
<A HREF="papers/ZLW.icassp21.pdf">
Complex ratio masking for singing voice separation</a>.
<cite>Proceedings of ICASSP-21</cite>, pp. 41-45.
<br><br>

<LI>Taherian H. and Wang D.L. (2021): 
<A HREF="papers/Taherian-Wang.icassp21.pdf">
Time-domain loss modulation based on overlap ratio for monaural conversational speaker separation</a>.
<cite>Proceedings of ICASSP-21</cite>, pp. 5744-5748.
<br><br>

<LI>Tan K., Zhang X., and Wang D.L. (2021): 
<A HREF="papers/TZW.icassp21.pdf">
Real-time speech enhancement for mobile communication based on dual-channel complex spectral mapping</a>.
<cite>Proceedings of ICASSP-21</cite>, pp. 6134-6138.
<br><br>

<LI>Tan K. and Wang D.L. (2021): 
<A HREF="papers/Tan-Wang.icassp21.pdf">
Compressing deep neural networks for efficient speech enhancement</a>.
<cite>Proceedings of ICASSP-21</cite>, pp. 8358-8362.
<br><br>

<LI>Li H., Wang D.L., Zhang X., and Gao G. (2020): 
<A HREF="papers/LWZG.interspeech20.pdf">
Frame-level signal-to-noise ratio estimation using deep learning</a>.
<cite>Proceedings of INTERSPEECH-20</cite>, pp. 4626-4630.
<br><br>

<LI>Pandey A. and Wang D.L. (2020): 
<A HREF="papers/Pandey-Wang.interspeech20.pdf">
Learning complex spectral mapping for speech enhancement with improved cross-corpus generalization</a>.
<cite>Proceedings of INTERSPEECH-20</cite>, pp. 4511-4515.
<br><br>

<LI>Zhao Y. and Wang D.L. (2020): 
<A HREF="papers/Zhao-Wang.interspeech20.pdf">
Noisy-reverberant speech enhancement using DenseUNet with time-frequency attention</a>.
<cite>Proceedings of INTERSPEECH-20</cite>, pp. 3261-3265.
<br><br>

<LI>Zhang H. and Wang D.L. (2020): 
<A HREF="papers/Zhang-Wang.interspeech20.pdf">
A deep learning approach to active noise control</a>.
<cite>Proceedings of INTERSPEECH-20</cite>, pp. 1141-1145.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2020): 
<A HREF="papers/ZWang-Wang.icassp20.pdf">
Multi-microphone complex spectral mapping for speech dereverberation</a>.
<cite>Proceedings of ICASSP-20</cite>, pp. 486-490.
<br><br>

<LI>Wang H. and Wang D.L. (2020): 
<A HREF="papers/HWang-Wang.icassp20.pdf">
Time-frequency loss for CNN based speech super-resolution</a>.
<cite>Proceedings of ICASSP-20</cite>, pp. 861-865.
<br><br>

<LI>Liu Y., Delfarah M., and Wang D.L. (2020): 
<A HREF="papers/LDW.icassp20.pdf">
Deep CASA for talker-independent monaural speech separation</a>.
<cite>Proceedings of ICASSP-20</cite>, pp. 6354-6358.
<br><br>

<LI>Pandey A. and Wang D.L. (2020): 
<A HREF="papers/Pandey-Wang.icassp20.pdf">
Densely connected neural network with dilated convolutions for real-time speech enhancement in the time domain</a>.
<cite>Proceedings of ICASSP-20</cite>, pp. 6629-6633.
<br><br>

<LI>Tan K. and Wang D.L. (2020): 
<A HREF="papers/Tan-Wang.icassp20.pdf">
Improving robustness of deep learning based monaural speech enhancement against processing artifacts</a>.
<cite>Proceedings of ICASSP-20</cite>, pp. 6914-6918.
<br><br>

<LI>Delfarah M., Liu Y., and Wang D.L. (2020): 
<A HREF="papers/DLW.icassp20.pdf">
Talker-independent speaker separation in reverberant conditions</a>.
<cite>Proceedings of ICASSP-20</cite>, pp. 8723-8727.
<br><br>

<LI>Wang P., Tan K., and Wang D.L. (2019): 
<A HREF="papers/WTW.interspeech19.pdf">
Bridging the gap between monaural speech enhancement and recognition with distortion-independent acoustic modeling</a>.
<cite>Proceedings of INTERSPEECH-19</cite>, pp. 471-475.
<br><br>

<LI>Wang P. and Wang D.L. (2019): 
<A HREF="papers/Wang-Wang.interspeech19.pdf">
Enhanced spectral features for distortion-independent acoustic modeling</a>.
<cite>Proceedings of INTERSPEECH-19</cite>, pp. 476-480.
<br><br>

<LI>Taherian H., Wang Z.-Q., and Wang D.L. (2019): 
<A HREF="papers/TWW.interspeech19.pdf">
Deep learning based multi-channel speaker recognition in noisy and reverberant environments</a>.
<cite>Proceedings of INTERSPEECH-19</cite>, pp. 4070-4074.
<br><br>

<LI>Zhang H., Tan K., and Wang D.L. (2019): 
<A HREF="papers/ZTW.interspeech19.pdf">
Deep learning for joint acoustic echo and noise cancellation with nonlinear distortions</a>.
<cite>Proceedings of INTERSPEECH-19</cite>, pp. 4255-4259.
<br><br>

<LI>Wang Z.-Q., Tan K., and Wang D.L. (2019): 
<A HREF="papers/WTW.icassp19.pdf">
Deep learning based phase reconstruction for speaker separation: A trigonometric perspective</a>.
<cite>Proceedings of ICASSP-19</cite>, pp. 71-75.
<br><br>

<LI>Xie J., Jin D., Zhang W, Zhang X.-L., Chen J., and Wang D.L. (2019): 
<A HREF="papers/XJZZCW.icassp19.pdf">
Robust sparse multichannel active noise control</a>.
<cite>Proceedings of ICASSP-19</cite>, pp. 521-525.
<br><br>

<LI>Tan K., Zhang X., and Wang D.L. (2019): 
<A HREF="papers/TZW.icassp19.pdf">
Real-time speech enhancement using an efficient convolutional recurrent network for dual-microphone mobile phones in close-talk scenarios</a>.
<cite>Proceedings of ICASSP-19</cite>, pp. 5751-5755.
<br><br>

<LI>Tan K. and Wang D.L. (2019): 
<A HREF="papers/Tan-Wang.icassp19.pdf">
Complex spectral mapping with a convolutional recurrent network for monaural speech enhancement</a>.
<cite>Proceedings of ICASSP-19</cite>, pp. 6865-6869.
<br><br>

<LI>Pandey A. and Wang D.L. (2019): 
<A HREF="papers/Pandey-Wang1.icassp19.pdf">
TCNN: Temporal convolutional neural network for real-time speech enhancement in the time domain</a>.
<cite>Proceedings of ICASSP-19</cite>, pp. 6875-6879.
<br><br>

<LI>Pandey A. and Wang D.L. (2019): 
<A HREF="papers/Pandey-Wang2.icassp19.pdf">
Exploring deep complex networks for complex spectrogram enhancement</a>.
<cite>Proceedings of ICASSP-19</cite>, pp. 6885-6889.
<br><br>

<LI>Pandey A. and Wang D.L. (2018): 
<A HREF="papers/Pandey-Wang.interspeech18.pdf">
A new framework for supervised speech enhancement in the time domain</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 1136-1140.
<br><br>

<LI>Tan K. and Wang D.L. (2018): 
<A HREF="papers/Tan-Wang1.interspeech18.pdf">
A convolutional recurrent neural network for real-time speech enhancement</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 3229-3233.
(Related <a href="https://web.cse.ohio-state.edu/~dwang/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Tan K. and Wang D.L. (2018): 
<A HREF="papers/Tan-Wang2.interspeech18.pdf">
A two-stage approach to noisy cochannel speech separation with gated residual networks</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 3484-3488.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2018): 
<A HREF="papers/Wang-Wang1.interspeech18.pdf">
Integrating spectral and spatial features for multi-channel speaker separation</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 2718-2722.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2018): 
<A HREF="papers/Wang-Wang2.interspeech18.pdf">
All-neural multi-channel speech enhancement</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 3234-3238.
<br><br>

<LI>Wang Z.-Q., Zhang X., and Wang D.L. (2018): 
<A HREF="papers/WZW.interspeech18.pdf">
Robust TDOA estimation based on time-frequency masking and deep neural networks</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 322-326.
<br><br>

<LI>Wang Z.-Q., Le Roux J., Wang D.L., Hershey, J.R. (2018): 
<A HREF="papers/WLWH.interspeech18.pdf">
End-to-end speech separation with unfolded iterative phase reconstruction</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 2708-2712.
<br><br>

<LI>Zhang H. and Wang D.L. (2018): 
<A HREF="papers/Zhang-Wang.interspeech18.pdf">
Deep learning for acoustic echo cancellation in noisy and double-talk scenarios</a>.
<cite>Proceedings of INTERSPEECH-18</cite>, pp. 3239-3243.
<br><br>

<LI>Chakrabarty S., Wang D.L., Habets E.A.P. (2018): 
<A HREF="papers/CWH.iwaenc18.pdf">
Time-frequency masking based online speech enhancement with multi-channel data using convolutional neural networks</a>.
<cite>Proceedings of IWAENC-18</cite>, pp. 476-480.
<br><br>

<LI>Delfarah M. and Wang D.L. (2018): 
<A HREF="papers/Delfarah-Wang.icassp18.pdf">
Recurrent neural networks for cochannel speech separation in reverberant environments</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5404-5408.
<br><br>

<LI>Liu Y. and Wang D.L. (2018): 
<A HREF="papers/Liu-Wang1.icassp18.pdf">
Permutation invariant training for speaker-independent multi-pitch tracking</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5594-5598.
<br><br>

<LI>Liu Y. and Wang D.L. (2018): 
<A HREF="papers/Liu-Wang2.icassp18.pdf">
A CASA approach to deep learning based speaker-independent co-channel speech separation</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5399-5403.
<br><br>

<LI>Pandey A. and Wang D.L. (2018): 
<A HREF="papers/Pandey-Wang.icassp18.pdf">
On adversarial training and loss functions for speech enhancement</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5414-5418.
<br><br>

<LI>Tan K., Chen J., and Wang D.L. (2018): 
<A HREF="papers/TCW.icassp18.pdf">
Gated residual networks with dilated convolutions for supervised speech separation</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 21-25.
<br><br>

<LI>Wang P. and Wang D.L. (2018): 
<A HREF="papers/PWang-Wang1.icassp18.pdf">
Filter-and-convolve: a CNN based multichannel complex concatenation acoustic model</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5564-5568.
<br><br>

<LI>Wang P. and Wang D.L. (2018): 
<A HREF="papers/PWang-Wang2.icassp18.pdf">
Utterance-wise recurrent dropout and iterative speaker adaptation for robust monaural speech recognition</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 4814-4818.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2018): 
<A HREF="papers/ZWang-Wang1.icassp18.pdf">
Mask weighted STFT ratios for relative transfer function estimation and its application to robust ASR</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5619-5623.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2018): 
<A HREF="papers/ZWang-Wang2.icassp18.pdf">
On spatial features for supervised speech separation and its application to beamforming and robust ASR</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5709-5713.
<br><br>

<LI>Zhao Y. Wang D.L., Xu B., and Zhang T. (2018): 
<A HREF="papers/ZWXZ.icassp18.pdf">
Late reverberation suppression using recurrent neural networks with long short-term memory</a>.
<cite>Proceedings of ICASSP-18</cite>, pp. 5434-5438.
<br><br>

<LI>Zhang X. and Wang D.L. (2017): 
<A HREF="papers/Zhang-Wang.interspeech17.pdf">
Binaural reverberant speech separation based on deep neural networks</a>.
<cite>Proceedings of INTERSPEECH-17</cite>, pp. 2018-2022.
<br><br>

<LI>Zhang X., Wang Z.-Q., and Wang D.L. (2017): 
<A HREF="papers/ZWW1.icassp17.pdf">
A speech enhancement algorithm by iterating single- and multi-microphone processing and its application to robust ASR</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 276-280.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2017): 
<A HREF="papers/Wang-Wang2.icassp17.pdf">
Unsupervised speaker adaptation of batch normalized acoustic models for robust ASR</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 4890-4894.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2017): 
<A HREF="papers/Wang-Wang1.icassp17.pdf">
Recurrent deep stacking networks for supervised speech separation</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 71-75.
<br><br>

<LI>Zhao Y., Wang Z.-Q., and Wang D.L. (2017): 
<A HREF="papers/ZWW2.icassp17.pdf">
A two-stage algorithm for noisy and reverberant speech enhancement</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 5580-5584.
<br><br>

<LI>Williamson D. and Wang D.L. (2017): 
<A HREF="papers/Williamson-Wang.icassp17.pdf">
Speech dereverberation and denoising using complex ratio masks</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 5590-5594.
<br><br>

<LI>Chang J. and Wang D.L. (2017): 
<A HREF="papers/Chang-Wang.icassp17.pdf">
Robust speaker recognition based on DNN/i-vectors and speech separation</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 5415-5419.
<br><br>

<LI>Liu Y. and Wang D.L. (2017): 
<A HREF="papers/Liu-Wang.icassp17.pdf">
Time and frequency domain long short-term memory for noise robust pitch tracking</a>.
<cite>Proceedings of ICASSP-17</cite>, pp. 5600-5604.
<br><br>

<LI>Chen J. and Wang D.L. (2016): 
<A HREF="papers/Chen-Wang.interspeech16.pdf">
Long short-term memory for speaker generalization in supervised speech separation</a>.
<cite>Proceedings of INTERSPEECH-16</cite>, pp. 3314-3318.
<br><br>

<LI>Delfarah M. and Wang D.L. (2016): 
<A HREF="papers/Delfarah-Wang.interspeech16.pdf">
A feature study for masking-based reverberant speech separation</a>.
<cite>Proceedings of INTERSPEECH-16</cite>, pp. 555-559.
<br><br>

<LI>Williamson D.S., Wang Y., and Wang D.L. (2016): 
<A HREF="papers/WWW.icassp16.pdf">
Complex ratio masking for joint enhancement of magnitude and phase</a>.
<cite>Proceedings of ICASSP-16</cite>, pp. 5220-5224.
<br><br>

<LI>Liu Y. and Wang D.L. (2016): 
<A HREF="papers/Liu-Wang.icassp16.pdf">
Robust pitch tracking in noisy speech using speaker-dependent deep neural networks</a>.
<cite>Proceedings of ICASSP-16</cite>, pp. 5255-5259.
<br><br>

<LI>Wang Z.-Q., Zhao Y., and Wang D.L. (2016): 
<A HREF="papers/WZW.icassp16.pdf">
Phoneme-specific speech separation</a>.
<cite>Proceedings of ICASSP-16</cite>, pp. 146-150.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2016): 
<A HREF="papers/Wang-Wang.icassp16.pdf">
Robust speech recognition from ratio masks</a>.
<cite>Proceedings of ICASSP-16</cite>, pp. 5720-5724.
<br><br>

<LI>Zhao Y., Wang D.L., Merks I., and Zhang T. (2016): 
<A HREF="papers/ZWMZ.icassp16.pdf">
DNN-based enhancement of noisy and reverberant speech</a>.
<cite>Proceedings of ICASSP-16</cite>, pp. 6525-6529.
<br><br>

<LI>Wang Z.-Q. and Wang D.L. (2015): 
<A HREF="papers/Wang-Wang.interspeech15.pdf">
Joint training of speech separation, filterbank and acoustic model for robust 
automatic speech recognition</a>.
<cite>Proceedings of INTERSPEECH-15</cite>, pp. 2839-2843.
<br><br>

<LI>Liu Y. and Wang D.L. (2015): 
<A HREF="papers/Liu-Wang.interspeech15.pdf">
Speaker-dependent multipitch tracking using deep neural networks</a>.
<cite>Proceedings of INTERSPEECH-15</cite>, pp. 3279-3283.
<br><br>

<LI>Zhang X.-L. and Wang D.L. (2015): 
<A HREF="papers/Zhang-Wang.interspeech15.pdf">
Multi-resolution stacking for speech separation based on boosted DNN</a>.
<cite>Proceedings of INTERSPEECH-15</cite>, pp. 1745-1749.
<br><br>

<LI>Han K., He Y., Bagchi D., Fosler-Lussier E., and Wang D.L. (2015): 
<A HREF="papers/HHBFW.interspeech15.pdf">
Deep neural network based spectral feature mapping for robust speech
recognition</a>.
<cite>Proceedings of INTERSPEECH-15</cite>, pp. 2484-2488.
<br><br>

<LI>Chen J., Wang, Y., and Wang D.L. (2015): 
<A HREF="papers/CWW.lva15.pdf">
Noise perturbation improves supervised speech separation</a>.
<cite>Proceedings of LVA/ICA-15</cite>, pp. 83-90.
<br><br>

<LI>Wang Y. and Wang D.L. (2015): 
<A HREF="papers/Wang-Wang.icassp15.pdf">
A deep neural network for time-domain signal reconstruction</a>.
<cite>Proceedings of ICASSP-15</cite>, pp. 4390-4394
(The first author, Yuxuan Wang, receives the 2015 <CITE>ICASSP</CITE> 
<FONT2>Starkey Signal Processing Research Award</FONT2> for this paper as a graduate student).
<br><br>

<LI>Zhao X., Wang Y., and Wang D.L. (2015): 
<A HREF="papers/ZWW.icassp15.pdf">
Deep neural networks for cochannel speaker identification</a>.
<cite>Proceedings of ICASSP-15</cite>, pp. 4824-4828.
<br><br>

<LI>Williamson D.S., Wang Y., and Wang (2015): 
<A HREF="papers/WWW.icassp15.pdf">
Deep neural networks for estimating speech model activations</a>.
<cite>Proceedings of ICASSP-15</cite>, pp. 5113-5117.
<br><br>

<LI>Zhang X.-L. and Wang D.L. (2014): 
<A HREF="papers/Zhang-Wang.interspeech14.pdf">
Boosted deep neural networks and multi-resolution cochleagram features for
voice activity detection</a>.
<cite>Proceedings of INTERSPEECH-14</cite>, pp. 1534-1538.
<br><br>

<LI>Jiang Y., Wang D.L., and Liu R.S. (2014): 
<A HREF="papers/JWL.interspeech14.pdf">
Binaural deep neural network classification for reverberant speech segregation</a>.
<cite>Proceedings of INTERSPEECH-14</cite>, pp. 2400-2404.
<br><br>

<LI>Han K. and Wang D.L. (2014): 
<A HREF="papers/Han-Wang.icassp14.pdf">
Neural networks for supervised pitch tracking in noise</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 1502-1506.
<br><br>

<LI>Han K., Wang Y., and Wang D.L. (2014): 
<A HREF="papers/HWW.icassp14.pdf">
Learning spectral mapping for speech dereverberation</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 4661-4665.
<br><br>

<LI>Williamson D.S., Wang Y., and Wang D.L. (2014): 
<A HREF="papers/WWW.icassp14.pdf">
A two-stage approach for improving the perceptual quality of separated speech</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 7084-7088.
<br><br>

<LI>Wang Y. and Wang D.L. (2014): 
<A HREF="papers/Wang-Wang.icassp14.pdf">
A structure-preserving training target for supervised speech separation</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 6148-6152.
<br><br>

<LI>Chen J., Wang, Y., and Wang D.L. (2014): 
<A HREF="papers/CWW.icassp14.pdf">
A feature study for classification-based speech separation at very low signal-to-noise ratio</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 7089-7093.
<br><br>

<LI>Zhao X., Wang Y., and Wang D.L. (2014): 
<A HREF="papers/ZWW.icassp14.pdf">
Robust speaker identification in noisy and reverberant conditions</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 4025-4029.
<br><br>

<LI>Narayanan A. and Wang D.L. (2014): 
<A HREF="papers/Narayanan-Wang.icassp14.pdf">
Joint noise adaptive training for robust automatic speech recognition</a>.
<cite>Proceedings of ICASSP-14</cite>, pp. 2523-2527.
<br><br>

<LI>Narayanan A. and Wang D.L. (2013): 
<A HREF="papers/Narayanan-Wang1.icassp13.pdf">
Coupling binary masking and robust ASR</a>.
<cite>Proceedings of ICASSP-13</cite>, pp. 6817-6821.
<br><br>

<LI>Narayanan A. and Wang D.L. (2013): 
<A HREF="papers/Narayanan-Wang2.icassp13.pdf">
Ideal ratio mask estimation using deep neural networks for robust speech recognition</a>.
<cite>Proceedings of ICASSP-13</cite>, pp. 7092-7096.
<br><br>

<LI>Williamson D.S., Wang Y. and Wang D.L. (2013): 
<A HREF="papers/WWW.icassp13.pdf">
A sparse representation approach for perceptual quality improvement of separated speech</a>.
<cite>Proceedings of ICASSP-13</cite>, pp. 7015-7019.
<br><br>

<LI>Zhao X. and Wang D.L. (2013): 
<A HREF="papers/Zhao-Wang.icassp13.pdf">
Analyzing noise robustness of MFCC and GFCC features in speaker identification</a>.
<cite>Proceedings of ICASSP-13</cite>, pp. 7204-7208.
<br><br>

<LI>Wang Y. and Wang D.L. (2013): 
<A HREF="papers/Wang-Wang.icassp13.pdf">
Feature denoising for speech separation in unknown noisy environments</a>.
<cite>Proceedings of ICASSP-13</cite>, pp. 7472-7476.
<br><br>

<LI>Han K. and Wang D.L. (2013): 
<A HREF="papers/Han-Wang.icassp13.pdf">
Learning invariant features for speech separation</a>.
<cite>Proceedings of ICASSP-13</cite>, pp. 7492-7496.
<br><br>

<LI>Wang Y. and Wang D.L. (2012): 
<A HREF="https://papers.nips.cc/paper/4838-cocktail-party-processing-via-structured-prediction">
Cocktail party processing via structured prediction</a>.
<cite>Proceedings of NIPS-12</cite>, pp. 224-232.
<br><br>

<LI>Wang Y. and Wang D.L. (2012): 
<A HREF="papers/Wang-Wang.interspeech12.pdf">
Boosting classification based speech separation using temporal dynamics</a>.
<cite>Proceedings of INTERSPEECH-12</cite>, pp. 1528-1531.
<br><br>

<LI>Wang Y., Han K., and Wang D.L. (2012): 
<A HREF="papers/WHW.interspeech12.pdf">
Acoustic features for classification based speech separation</a>.
<cite>Proceedings of INTERSPEECH-12</cite>, pp. 1532-1535.
<br><br>

<LI>Narayanan A. and Wang D.L. (2012): 
<A HREF="papers/Narayanan-Wang.interspeech12.pdf">
On the role of binary mask pattern in automatic speech recognition</a>.
<cite>Proceedings of INTERSPEECH-12</cite>, pp. 1239-1242.
<br><br>

<LI>Hu K. and Wang D.L. (2012): 
<A HREF="papers/Hu-Wang.icassp12.pdf">
SVM-based separation of unvoiced-voiced speech in cochannel conditions</a>.
<cite>Proceedings of ICASSP-12</cite>, pp. 4545-4548.
<br><br>

<LI>Han K. and Wang D.L. (2012): 
<A HREF="papers/Han-Wang.icassp12.pdf">
On generalization of classification based speech separation</a>.
<cite>Proceedings of ICASSP-12</cite>, pp. 4541-4544.
<br><br>

<LI>Woodruff J. and Wang D.L. (2012): 
<A HREF="papers/Woodruff-Wang.icassp12.pdf">
Binaural speech segregation based on pitch and azimuth tracking</a>.
<cite>Proceedings of ICASSP-12</cite>, pp. 241-244.
<br><br>

<LI>Yuan J., Wang D.L., and Li R. (2011):
<A HREF="papers/YWL.ijcnn11.pdf">
Image segmentation based on local spectral histograms and linear regression</a>.
<cite>Proceedings of IJCNN-11</cite>, pp. 482-488.
<br><br>

<LI>Woodruff J. and Wang D.L. (2011): 
<A HREF="papers/Woodruff-Wang.icassp11.pdf">
Directionality-based speech enhancement for hearing aids</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 297-300.
<br><br>

<LI>Hsu C.-L., Wang D.L., and Jang J.-S.R. (2011): 
<A HREF="papers/HWJ.icassp11.pdf">
A trend estimation algorithm for singing pitch detection in musical recordings</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 393-396.
<br><br>

<LI>Narayanan A. and Wang D.L. (2011): 
<A HREF="papers/Narayanan-Wang.icassp11.pdf">
On the use of ideal binary masks for improving phonetic classification</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 4632-4635.
<br><br>

<LI>Hu K. and Wang D.L. (2011): 
<A HREF="papers/Hu-Wang.icassp11.pdf">
An approach to sequential grouping in cochannel speech</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 4636-4639.
<br><br>

<LI>Narayanan A., Zhao X., Wang D.L., and Fosler-Lussier E. (2011): 
<A HREF="papers/NZWF.icassp11.pdf">
Robust speech recognition using multiple prior models for speech reconstruction</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 4800-4803.
<br><br>

<LI>Han K. and Wang D.L. (2011): 
<A HREF="papers/Han-Wang.icassp11.pdf">
An SVM based classification approach to speech separation</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 5212-5215.
<br><br>

<LI>Zhao X., Shao Y., and Wang D.L. (2011): 
<A HREF="papers/ZSW.icassp11.pdf">
Robust speaker identification using a CASA front-end</a>.
<cite>Proceedings of ICASSP-11</cite>, pp. 5468-5471.
<br><br>

<LI>Woodruff J., Prabhavalkar R., Fosler-Lussier E., and Wang D.L. (2010): 
<A HREF="papers/WPFW.interspeech10.pdf">
Combining monaural and binaural evidence for reverberant speech segregation</a>.
<cite>Proceedings of INTERSPEECH-10</cite>, pp. 406-409.
<br><br>

<LI>Hu K. and Wang D.L. (2010): 
<A HREF="papers/Hu-Wang.interspeech10a.pdf">
Unvoiced speech segregation based on CASA and spectral subtraction</a>.
<cite>Proceedings of INTERSPEECH-10</cite>, pp. 2786-2789.
<br><br>

<LI>Hu K. and Wang D.L. (2010): 
<A HREF="papers/Hu-Wang.interspeech10b.pdf">
Unsupervised sequential organization for cochannel speech separation</a>.
<cite>Proceedings of INTERSPEECH-10</cite>, pp. 2790-2793.
<br><br>

<LI>Kjems U., Pedersen M.S., Boldt J.B., Lunner T., and Wang D.L. (2010): 
<A HREF="papers/KPBLW.eusipco10.pdf">
Speech intelligibility of ideal binary masked mixtures</a>.
<cite>Proceedings of EUSIPCO-10</cite>, pp. 1909-1913.
<br><br>

<LI>Yan L., Yuan J., Cheng L., Wang D.L., Li R. (2010): 
<A HREF="papers/YYCWL.asprs10.pdf">
A biologically and geometrically inspired approach to target extraction from multiple-source remote-sensing imagery</a>.
<cite>Proceedings of ASPRS-10</cite>.
<br><br>

<LI>Jin Z. and Wang D.L. (2010): 
<A HREF="papers/Jin-Wang.icassp10.pdf">
A multipitch tracking algorithm for noisy and reverberant speech</a>.
<cite>Proceedings of ICASSP-10</cite>, pp. 4218-4221.
<br><br>

<LI>Woodruff J. and Wang D.L. (2010): 
<A HREF="papers/Woodruff-Wang.icassp10.pdf">
Integrating monaural and binaural analysis for localizing multiple reverberant
sound sources</a>.
<cite>Proceedings of ICASSP-10</cite>, pp. 2706-2709.
<br><br>

<LI>Quiles M.G., Wang D.L., Zhao L., Romero R.A.F., and Huang D.-S. (2009):
<A HREF="papers/QWZRH.ijcnn09.pdf">
An oscillatory correlation model of object-based attention</a>.
<cite>Proceedings of IJCNN-09</cite>, pp. 2596-2602.
<br><br>

<LI>Yuan J., Wang D.L., Wu B., Yan L., and Li R. (2009):
<A HREF="papers/YWWYL.ijcnn09.pdf">
Automatic road extraction from satellite imagery using LEGION networks</a>.
<cite>Proceedings of IJCNN-09</cite>, pp. 3471-3476.
<br><br>

<LI>Jan T., Wang W., Wang D.L. (2009):
<A HREF="papers/JWW.icassp09.pdf">
A multistage approach for blind separation of convolutive speech mixtures</a>.
<cite>Proceedings of ICASSP-09</cite>, pp. 1713-1716.
<br><br>

<LI>Woodruff J. and Wang D.L. (2009): 
<A HREF="papers/Woodruff-Wang.icassp09.pdf">
On the role of localization cues in binaural segregation of reverberant speech</a>.
<cite>Proceedings of ICASSP-09</cite>, pp. 2205-2208.
<br><br>

<LI>Hu K. and Wang D.L. (2009): 
<A HREF="papers/Hu-Wang.icassp09.pdf">
Incorporating spectral subtraction and noise type for unvoiced speech segregation</a>.
<cite>Proceedings of ICASSP-09</cite>, pp. 4425-4428.
<br><br>

<LI>Shao Y., Jin Z., Wang D.L., and Srinivasan S. (2009):
<A HREF="papers/SJWS.icassp09.pdf">
An auditory-based feature for robust speech recognition</a>.
<cite>Proceedings of ICASSP-09</cite>, pp. 4625-4628.
<br><br>

<LI>Jin Z. and Wang D.L. (2009): 
<A HREF="papers/Jin-Wang.icassp09.pdf">
Learning to maximize signal-to-noise ratio for reverberant speech segregation</a>.
<cite>Proceedings of ICASSP-09</cite>, pp. 4689-4692.
<br><br>

<LI>Wu B., Zhou Y., Yan L., Yuan J., Li R. and Wang D.L. (2009): 
<A HREF="papers/WZYYLW-asprs09.pdf">
Object detection from HS/MS and multi-platform remote sensing imagery by the integration of biologically and geometrically inspired approaches</a>.
<cite>Proceedings of ASPRS-09</cite>.
<br><br>

<LI>Hu K., Divenyi P., Ellis D.P.W., Jin Z., Shinn-Cunningham B.G., and Wang D.L. (2008): <a href="http://www.sapa2008.org/papers/112.pdf">Preliminary intelligibility tests of a monaural speech segregation system</a>. 
<cite>ISCA Tutorial and Research Workshop on Statistical and 
Perceptual Audition (SAPA-08)</cite>.
<br><br> 

<LI>Woodruff J., Li Y., and Wang D.L. (2008): 
<A HREF="papers/WLW.ismir08.pdf">
Resolving overlapping harmonics for monaural musical sound separation using pitch and common amplitude modulation</a>.
<cite>Proceedings of ISMIR-08</cite>, pp. 538-543.
(Related <a href="https://web.cse.ohio-state.edu/~woodrufj/mmss.html">Sound Demo</a>.)
<br><br>

<LI>Boldt J.B., Kjems U., Pedersen M.S., Lunner T., and Wang D.L. (2008): 
<A HREF="papers/BKPLW.iwaenc08.pdf">
Estimation of the ideal binary mask using directional systems</a>.
<cite>Proceedings of IWAENC-08</cite>.
<br><br>

<LI>Li Y. and Wang D.L. (2008): 
<A HREF="papers/Li-Wang.icassp08b.pdf">
Musical sound separation using pitch-based labeling and binary 
time-frequency masking</a>.
<cite>Proceedings of ICASSP-08</cite>, pp. 173-176.
<br><br>

<LI>Li Y. and Wang D.L. (2008): 
<A HREF="papers/Li-Wang.icassp08a.pdf">
On the optimality of ideal binary time-frequency masks</a>.
<cite>Proceedings of ICASSP-08</cite>, pp. 3501-3504.
<br><br>

<LI>Shao Y. and Wang D.L. (2008): 
<A HREF="papers/Shao-Wang.icassp08.pdf">
Robust speaker identification using auditory features and computational 
auditory scene analysis</a>.
<cite>Proceedings of ICASSP-08</cite>, pp. 1589-1592.
<br><br>

<LI>Jin Z. and Wang D.L. (2007): 
<A HREF="papers/Jin-Wang.icassp07.pdf">
A supervised learning approach to monaural segregation of reverberant speech</a>.
<cite>Proceedings of ICASSP-07</cite>, pp. IV.921-924.
<br><br>

<LI>Li Y. and Wang D.L. (2007): 
<A HREF="papers/Li-Wang.icassp07.pdf">
Pitch detection in polyphonic music using instrument tone models</a>.
<cite>Proceedings of ICASSP-07</cite>, pp. II.481-484.
<br><br>

<LI>Shao Y., Srinivasan S., and Wang D.L. (2007): 
<A HREF="papers/SSW.icassp07.pdf">
Incorporating auditory feature uncertainties in robust speaker identification</a>.
<cite>Proceedings of ICASSP-07</cite>, pp. IV.277-280. (Related <a href="https://pnlwang.github.io/pnl/software.html">Source Code</a>.)
<br><br>

<LI>Srinivasan S., Roman N., and Wang D.L. (2007):
<A HREF="papers/SRW.icassp07.pdf">
Exploiting uncertainties for binaural speech recognition</a>.
<cite>Proceedings of ICASSP-07</cite>, pp. IV.789-792.
<br><br>

<LI>Li Y. and Wang D.L. (2006):
<A HREF="papers/Li-Wang.ismir06.pdf">
Singing voice separation from monaural recordings</a>.
<cite>Proceedings of ISMIR-06</cite>, pp. 176-179.
<br><br>

<LI>Srinivasan S., Shao Y., Jin Z., and Wang D.L. (2006):
<A HREF="papers/SSJW.interspeech06.pdf">
A computational auditory scene analysis system for robust speech recognition</a>.
<cite>Proceedings of Interspeech-06</cite>, pp. 73-76.
<br><br>

<LI>Roman N., Srinivasan S., and Wang D.L. (2006):
<A HREF="papers/RSW.icassp06.pdf">
Speech recognition in multisource reverberant environments with binaural inputs</a>.
<cite>Proceedings of ICASSP-06</cite>, pp. I.309-312.
<br><br>

<LI>Srinivasan S. and Wang D.L. (2006):
<A HREF="papers/Sriniv-Wang.icassp06.pdf">
A supervised learning approach to uncertainty decoding for robust speech recognition</a>.
<cite>Proceedings of ICASSP-06</cite>, pp. I.297-300.
<br><br>

<LI>Shao Y. and Wang D.L. (2006): 
<A HREF="papers/Shao-Wang.icassp06.pdf">
Robust speaker recognition using binary time-frequency masks</a>.
<cite>Proceedings of ICASSP-06</cite>, pp. I.645-648.
<br><br>

<LI>Wang D.L. and Hu G. (2006):
<A HREF="papers/Wang-Hu.icassp06.pdf">
Unvoiced speech segregation</a>.
<cite>Proceedings of ICASSP-06</cite>, pp. V.953-956.
<br><br>

<LI>Pedersen M.S., Wang D.L., Larsen J., and Kjems U. (2006):
<A HREF="papers/PWLK.ica06.pdf">
Separating underdetermined convolutive speech mixtures</a>.
<cite>Proceedings of Independent Component Analysis and Blind Signal Separation</cite>, pp. 674-681.
<br><br>

<LI>Pedersen M.S., Wang D.L., Larsen J., and Kjems U. (2005):
<A HREF="papers/PWLK.mlsp05.pdf">
Overcomplete blind source separation by combining ICA and binary
time-frequency masking</a>.
<cite>Proceedings of IEEE Workshop on Machine Learning for Signal Processing</cite>, pp. 15-20.
(Related <a href="http://www.imm.dtu.dk/~msp">
Sound Demo</a>.)
<br><br>

<LI>Roman N. and Wang D.L. (2005):
<A HREF="papers/Roman-Wang.is05.pdf">
A pitch-based model for separation of reverberant speech</a>.
<cite>Proceedings of Interspeech-05</cite>, pp. 2109-2112.
<br><br>

<LI>Srinivasan S. and Wang D.L. (2005):
<A HREF="papers/Sriniv-Wang.is05.pdf">
Modeling the perception of multitalker speech</a>.
<cite>Proceedings of Interspeech-05</cite>, pp. 1265-1268.
<br><br>

<LI>Srinivasan S. and Wang D.L. (2005):
<A HREF="papers/Sriniv-Wang.icassp05.pdf">
Robust speech recognition by integrating speech separation
and hypothesis testing</a>.
<cite>Proceedings of ICASSP-05</cite>, pp. I.89-92.
<br><br>

<LI>Hu G. and Wang D.L. (2005):
<A HREF="papers/Hu-Wang.icassp05.pdf">
Separation of fricatives and affricates</a>.
<cite>Proceedings of ICASSP-05</cite>, pp. I.1001-1004.
<br><br>

<LI>Wu M. and Wang D.L. (2005):
<A HREF="papers/Wu-Wang.icassp05.pdf">
A two-state algorithm for enhancement of reverberant speech</a>.
<cite>Proceedings of ICASSP-05</cite>, pp. I.1085-1088.
<br><br>

<LI>Li Y. and Wang D.L. (2005):
<A HREF="papers/Li-Wang.icassp05.pdf">
Detecting pitch of singing voice in polyphonic audio</a>.
<cite>Proceedings of ICASSP-05</cite>, pp. III.17-20.
<br><br>

<LI>Shao Y. and Wang D.L. (2004):
<A HREF="https://web.cse.ohio-state.edu/~shaoy/yang_ICSLP04.pdf">
Model-based sequential organization for cochannel speaker identification</A>. 
<cite>Proceedings of ICSLP-04</cite>. 
<br><br>

<LI>Srinivasan S., Roman N., and Wang D.L. (2004):
<A HREF="https://web.cse.ohio-state.edu/~srinivso/srinivasannikiwang.pdf">
On binary and ratio time-frequency masks for robust speech recognition</A>. 
<cite>Proceedings of ICSLP-04</cite>. 
<br><br>

<LI>Hu G. and Wang D.L. (2004): <a href="papers/Hu-Wang.sapa04.pdf">Auditory segmentation based on event detection</a>. 
<cite>ISCA Tutorial and Research Workshop on Statistical and 
Perceptual Audio Processing (SAPA-4)</cite>.
<br><br> 

<LI>Wang D.L. (2004): 
<A HREF="papers/Wang.ijcnn04.pdf">
A comparison of CNN and LEGION networks</a>.
<cite>Proceedings of IJCNN-04</cite>, pp. 1735-1740.
<br><br>

<LI>Roman N. and Wang D.L. (2004):
<A HREF="papers/Roman-Wang.icassp04.pdf">
Binaural sound segregation for multisource reverberant environments</a>.
<cite>Proceedings of ICASSP-04</cite>, pp. II.373-376.
<br><br>

<LI>Roman N., Wang D.L., and Brown G.J. (2004): 
<A HREF="papers/RWB.nips03.pdf">
A classification-based cocktail-party processor</a>.
<cite>Proceedings of NIPS-03</cite>.
(Related <a href="https://web.cse.ohio-state.edu/~niki/soundemo.html">
Sound Demo</a>.)
<br><br>

<LI>Srinivasan S. and Wang D.L. (2003):
<A HREF="papers/Sriniv-Wang.eurospeech03.pdf">
Schema-based modeling of phonemic restoration</a>.
<cite>Proceedings of EUROSPEECH-03</cite>, pp. 2053-2056.
<br><br>

<LI>Liu X., Srivastava A., and Wang D.L. (2003): 
<A HREF="papers/LSW.ijcnn03.pdf">
On intrinsic generalization of low dimensional representations
of images for recognition</A>.
<cite>Proceedings of IJCNN-03</cite>, pp. 182-187.
<br><br>

<LI>Roman N. and Wang D.L. (2003):
<A HREF="papers/Roman-Wang.icassp03.pdf">
Binaural tracking of multiple moving sources</a>.
<cite>Proceedings of ICASSP-03</cite>, pp. V.149-152.
<br><br>

<LI>Wu M. and Wang D.L. (2003): 
<A HREF="papers/Wu-Wang.icassp03.pdf">
A one-microphone algorithm for reverberant speech enhancement</a>.
<cite>Proceedings of ICASSP-03</cite>, pp. I. 844-847.
<br><br>

<LI>Hu G. and Wang D.L. (2003): 
<A HREF="papers/Hu-Wang.icassp03.pdf">
Separation of stop consonants</a>.
<cite>Proceedings of ICASSP-03</cite>, pp. II.749-752.
<br><br>

<LI>Shao Y. and Wang D.L. (2003): 
<A HREF="papers/Shao-Wang.icassp03.pdf">
Co-channel speaker identification using usable speech extraction based 
on multi-pitch tracking</a>.
<cite>Proceedings of ICASSP-03</cite>, vol. II.205-208.
<br><br>

<LI>Hu G. and Wang D.L. (2003): 
<A HREF="papers/Hu-Wang.nips02.pdf">
Monaural speech separation</a>.
<cite>Proceedings of NIPS-02</cite>.
(Related <a href="https://web.cse.ohio-state.edu/~hu/Publication/MSSDemo.htm">
Sound Demo</a>.)
<br><br>

<LI>Roman N., Wang D.L., and Brown G.J. (2002):
<A HREF="papers/RWB.icassp02.pdf">
Localization-based sound segregation</a>.
<cite>Proceedings of ICASSP-02</cite>, pp. I.1013-1016.
<br><br>

<LI>Hu G. and Wang D.L. (2002): 
<A HREF="papers/Hu-Wang.icassp02.pdf">
Monaural speech segregation based on pitch tracking and amplitude 
modulation</a>.
<cite>Proceedings of ICASSP-02</cite>, pp. I.553-556.
<br><br>

<LI>Wu M., Wang D.L., and Brown G.J. (2002): 
<A HREF="papers/WWB.icassp02.pdf">
A multi-pitch tracking algorithm for noisy speech</a>.
<cite>Proceedings of ICASSP-02</cite>, pp. I.369-372.
<br><br>

<LI>Roman N., Wang D.L., and Brown G.J. (2002): 
<A HREF="papers/RWB.ijcnn02.pdf">
Localization-based sound segregation</a>.
<cite>Proceedings of IJCNN-02</cite>, pp. 2299-2303.
<br><br>

<LI>Hu G. and Wang D.L. (2002): 
<A HREF="papers/Hu-Wang.ijcnn02.pdf">
On amplitude modulation for monaural speech segregation</a>.
<cite>Proceedings of IJCNN-02</cite>, pp. 69-74 .
<br><br>

<LI>Chen K., Wang D.L., and Liu X. (2001):
Image segmentation by weight adaptation and oscillatory correlation.
<cite>Proceedings of International Conference on Neural Information Processing</cite>, invited paper.
<br><br>

<LI>Liu X., Wang D.L., Srivastava A. (2001):
<A HREF="papers/LWS.icip01.pdf">
Image segmentation using local spectral histograms</a>. 
<cite>Proceedings of International Conference on Image Processing</cite>, 
pp. 70-73.
<br><br>

<LI>Palomaki K., Brown G.J., and Wang D.L. (2001): 
<A HREF="papers/PBW.crac01.pdf">
A binaural model for missing data speech recognition in noisy and 
reverberant conditions</a>.
<cite>Web Proceedings of Workshop on Consistent and Reliable Acoustic Cues 
for Sound Analysis</cite>.
<br><br>

<LI>Hu G. and Wang D.L. (2001): 
<A HREF="papers/Hu-Wang.waspaa01.pdf">
Speech segregation based on pitch tracking and amplitude modulation</a>.
<cite>Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA-01) </cite>, pp. 79-82.
<br><br>

<LI>Brown G.J., Barker J., and Wang D.L. (2001): 
<A HREF="papers/BBW.ijcnn01.pdf">
A neural oscillator sound separator for missing data speech 
recognition</a>. 
<cite>Proceedings of IJCNN-01</cite>, pp. 2907-2912.
<br><br>

<LI>Roman N., Wang D.L., and Brown G.J. (2001): 
<A HREF="papers/RWB.ijcnn01.pdf">
Speech segregation based on sound localization</a>.
<cite>Proceedings of IJCNN-01</cite>, pp. 2861-2866.
<br><br>

<LI>Liu X. and Wang D.L. (2001): 
<A HREF="papers/Liu-Wang2.ijcnn01.pdf">
Appearance-based recognition using perceptual components</a>.
<cite>Proceedings of IJCNN-01</cite>, pp. 1943-1948.
<br><br>

<LI>Hu G. and Wang D.L. (2001): 
<A HREF="papers/Hu-Wang.ijcnn01.pdf">
An extended model for speech segregation</a>.
<cite>Proceedings of IJCNN-01</cite>, pp. 1089-1094.
<br><br>

<LI>Liu X. and Wang D.L. (2001): 
<A HREF="papers/Liu-Wang1.ijcnn01.pdf">
A spectral histogram model for textons and texture 
discrimination</a>.
<cite>Proceedings of IJCNN-01</cite>, pp. 1083-1088.
<br><br>

<LI>Wu M., Wang D.L., and Brown G.J. (2001): 
<A HREF="papers/WWB.ijcnn01.pdf">
Pitch tracking based on statistical anticipation</a>. 
<cite>Proceedings of IJCNN-01</cite>, pp. 866-871.
<br><br>

<LI>Liu X. and Wang D.L. (2000): Spectral histograms for texton modeling 
and discrimination.
<cite>Proceedings of the Sixteenth World Computer Congress 
(Intelligent Information Processing)</cite>, pp. 202-205.
<br><br>

<LI>Cesmeli E., Lindsey D.L., and Wang D.L. (2000): 
<A HREF="papers/CLW.ijcnn00.pdf">
An oscillatory correlation model of human motion perception</a>.
<cite>Proceedings of IJCNN-00</cite>, pp. IV.267-IV.272.
<br><br>

<LI>Brown G.J. and Wang D.L. (2000): 
<A HREF="papers/Brown-Wang.nips99.pdf">An oscillatory correlation 
framework for computational auditory scene analysis</a>. 
<cite>Proceedings of NIPS-99</cite>, pp. 747-753.
<br><br>

<LI>Liu X. and Wang D.L. (2000): 
<A HREF="papers/Liu-Wang.nips99.pdf">Perceptual organization based on 
temporal dynamics</a>. <cite>Proceedings of NIPS-99</cite>, 38-44.
<br><br>

<LI>Chen K. and Wang D.L. (1999): 
<A HREF="papers/Chen-Wang.nips98.ps.gz">
Perceiving without learning: from spirals to
 inside/outside relations</a>. <cite>Advances in Neural Information Processing 
Systems 11 (NIPS-98)</cite>, pp. 10-16.
<br><br>

<LI>Liu X. and Wang D.L. (1999): 
<A HREF="papers/Liu-Wang2.ijcnn99.pdf.gz">
Perceptual organization based on temporal dynamics</a>. 
<cite>Proceedings of IJCNN-99</cite>.
<br><br>

<LI>Liu X. and Wang D.L. (1999): 
<A HREF="papers/Liu-Wang1.ijcnn99.pdf.gz">
A boundary pair representation for perception modeling</a>. 
<cite>Proceedings of IJCNN-99</cite>.
<br><br>

<LI>Cesmeli E. and Wang D.L. (1999): 
<A HREF="papers/CesmeliW.ijcnn99.pdf.gz">
Image segmentation based on 
motion/luminance integration and oscillatory correlation</a>.
<cite>Proceedings of IJCNN-99</cite>.
<br><br>

<LI>Brown G.J. and Wang D.L. (1999): 
<A HREF="papers/Brown-Wang.ijcnn99.pdf.gz">
The separation of speech from 
interferring sounds: an oscillatory correlation approach</a>. 
<cite>Proceedings of IJCNN-99</cite>.
<br><br>

<LI>Chen K. and Wang D.L. (1999): 
<A HREF="papers/Chen-Wang.ijcnn99.pdf.gz">
Image segmentation based on a dynamically 
coupled neural oscillator network</a>. 
<cite>Proceedings of IJCNN-99</cite>.
<br><br>

<LI>Wang D.L. (1998): 
<A HREF="papers/Wang.ijcnn98.pdf.gz">
Object selection by oscillatory correlation</a> 
<cite>Proceedings of IJCNN-98</cite>, pp. 1182-1187.
<br><br>

<LI>Campbell S. and Wang D.L. (1998): 
<A HREF="papers/Campbell-Wang.ijcnn98.pdf.gz">
Synchrony and desynchrony in integrate-and-fire 
oscillators</a>. <cite>Proceedings of IJCNN-98</cite>, pp. 1498-1503.
<br><br>

<LI>Liu X.W., Wang D.L., and Ramirez J.R. (1998): 
<A HREF="papers/LWR.ijcnn98.pdf.gz">
Extracting hydrographic 
objects from satellite images using a two-layer neural network</a>.
<cite>Proceedings of IJCNN-98</cite>, pp. 897-902.
<br><br>

<LI>Chen K. and Wang D.L. (1998): 
<A HREF="papers/Chen-Wang.ijcnn98.pdf.gz">
Perceiving spirals and inside/outside 
relations by a neural oscillator network</a>. 
<cite>Proceedings of IJCNN-98</cite>, pp.619-624.
<br><br>

<LI>Cesmeli E., Wang D.L., Lindsey D.L., and Todd J.T. (1998): 
<A HREF="papers/CWLT.ijcnn98.pdf.gz">
Motion segmentation using temporal block matching and LEGION</a>.
<cite>Proceedings of IJCNN-98</cite>, 2069-2074.
<br><br>

<LI>Liu X., Wang D.L., and Ramirez J R. (1998): 
A two-layer neural network 
for robust image segmentation and its application in revising hydrographic 
features. <cite>International Archives of Photogrammetry and Remote 
Sensing</cite>, 
vol. 32, part 3/1, pp. 464-472.
<br><br>

<LI>Liu X., Wang D.L., and Ramirez J.R. (1998):
Oriented statistical nonlinear smoothing filter. <cite>Proceedings of the International Conference on 
Image Processing</cite>, vol. 2, pp. 848-852.
<br><br>

<LI>Cesmeli E. and Wang D.L. (1998):
"Gauss Markov Rasgele Alanlari ve 
Salingan Sinir Aglariyla Doku Bolutlemesi," <cite>SIU-98</cite>, Ankara 
TURKEY (in Turkish).
<br><br>

<LI>van der Kouwe A.J.W. and Wang D.L. (1997):
 Temporal alignment, spatial 
spread and the linear independence criterion for blind separation of voices.  
<CITE>Proceedings of IEEE EMBS</CITE>, pp. 1994-1996.
<br><br>

<LI>Wang D.L. (1997): 
Object selection by a neural oscillator network. 
<CITE>Proceedings of International Conference on Neural Information 
Processing</CITE>, pp. 1137-1140.
<br><br>

<LI>Liu X.W. and Wang D.L. (1997): 
Range image segmentation using an 
oscillatory network. <CITE>Proceedings of ICNN-97</CITE>, pp. 1656-1660.
<br><br>

<LI>Cesmeli E. and Wang D.L. (1997):
Texture segmentation using Gaussian 
Markov random fields and LEGION. <CITE>Proceedings of ICNN-97</CITE>, 
pp. 1529-1534.
<br><br>

<LI>Campbell S. and Wang D.L. (1997): 
Relaxation oscillator networks with 
time delays. <CITE>Proceedings of ICNN-97</CITE>, pp. 645-650.
<br><br>

<LI>Brown G.J. and Wang D.L. (1997):
Modelling the perceptual separation of 
concurrent vowels with a network of neural oscillators. 
<CITE>Proceedings of ICNN-97</CITE>, pp. 569-574.
<br><br>

<LI>Wang D.L. and Yuwono B. (1996): 
Incremental learning of complex temporal patterns. <CITE>Proceedings of WCNN-96</CITE>, pp. 757-762.
<br><br>

<LI>Shareef N., Wang D.L., and Yagel R. (1996):
Segmentation of medical data using locally excitatory globally inhibitory oscillator networks.
 <CITE>Proceedings of WCNN-96</CITE>, pp. 1245-1248.
<br><br>

<LI>Campbell S. and Wang D.L. (1996):
Loose synchrony in networks of relaxation oscillators with time delays. <CITE>Proceedings of 
WCNN-96</CITE>, pp. 717-720.
<br><br>

<LI>Wang D.L. and Yuwono B. (1996): 
A neural model of sequential memory. <CITE>Proceedings of ICNN-96</CITE>, pp. 828-833.
<br><br>

<LI>Campbell S. and Wang D.L. (1996): 
Loose synchrony in relaxation oscillator networks with time delays. <CITE>Proceedings of ICNN-96</CITE>, 
        pp. 828-833.
<br><br>

<LI>Wang D.L. and Terman D. (1996): 
Image segmentation by neural oscillator 
        networks. <CITE>Proceedings of ICNN-96</CITE>, pp. 1534-1539. 
<br><br>

<LI>Wang D.L. and D. Terman. (1995): 
Image segmentation by a neural 
        oscillator network. <CITE>Proceedings of International Conference
        on Neural Information Processing</CITE>, pp. 722-726. 
<br><br>

<LI>Campbell S. and D.L. Wang (1995): 
Relaxation oscillators with time 
        delay coupling. <CITE>
        Proceedings of WCNN-95</CITE>, pp. I. 258-261. 
<br><br>

<LI>Wang D.L. and D. Terman. (1995): 
Image segmentation based on 
        oscillatory correlation. <CITE>
        Proceedings of WCNN-95</CITE>, pp. II.521-525. 
<br><br>

<LI>Liu X.M., D.L. Wang and S.C. Ahalt (1995): 
On the temporal
        generalization capability of simple recurrent networks. <CITE>
        Proceedings of the 1995 SPIE Conference on Applications and Science
        of Artificial Neural Networks IV</CITE>. Orlando FL, pp. 392-403. 
<br><br>

<LI>Wang D.L. and Terman D. (1994):
 Locally excitatory globally inhibitory 
        oscillator networks: Theory and application to pattern segmentation. 
        <CITE>Proceedings of IEEE Conference on Neural Networks for Signal 
        Processing</CITE>, pp. 136-145.
<br><br>

<LI>Wang D.L. (1994): 
Auditory stream segregation based on oscillatory 
        correlation. <CITE>Proceedings of IEEE Conference on Neural Networks 
for Signal Processing</CITE>, pp. 624-632.
<br><br>

<LI>D.L. Wang and D. Terman (1994):
 Synchrony and desynchrony in neural 
        oscillator networks. <CITE>Advances in Neural Information Processing 
        Systems 7</CITE> (NIPS-94), pp. 199-206. 
<br><br>

<LI>D.L. Wang and D. Terman (1994): 
Locally excitatory globally inhibitory 
        oscillator networks: Theory and application to scene segmentation.
        <CITE>Proceedings of the 23rd Artificial Intelligence and Pattern 
        Recognition Workshop</CITE>, SPIE Proceedings 2368, pp. 624-632.
<br><br>

<LI>Wang D.L. (1994): 
An oscillation model of auditory stream segregation.
        <CITE>Proceedings of the International Conference on Pattern 
Recognition</CITE>, pp. C.198-200. Jerusalem, Israel.
<br><br>

<LI>Wang D.L. (1994):
 Modeling global synchrony in the visual cortex by 
        locally coupled neural oscillators. In: Eeckman F.H. (ed.), 
        <CITE>Proceedings of CNS-93</CITE>, pp. 109-114, Kluwer.
<br><br>

<LI>Wang D.L. and Terman D. (1994): 
Locally excitatory globally inhibitory
        oscillator networks: Theory and application to pattern segmentation. 
        <CITE>Proceedings of ICNN-94</CITE>, pp. 945-950. Orlando, FL.
<br><br>

<LI>Campbell S. and Wang D.L. (1994): 
Synchronization and desynchronization 
        in locally coupled Wilson-Cowan oscillators. <CITE>Proceedings of  
ICNN-94</CITE>, pp. 964-969.
<br><br>

<LI>Wang D.L. and Yuwono B. (1994): 
Temporal pattern generation based on 
        anticipation. <CITE>Proceedings of ICNN-94</CITE>, pp. 3148-3153.
<br><br>

<LI>Wang D.L. and Terman D. (1994): 
Locally excitatory globally inhibitory 
        oscillator networks.<CITE> Proceedings of WCNN-94</CITE>, 
pp. IV. 745-750. San Diego, CA.
<br><br>

<LI>Wang D.L. and Yuwono B. (1994): 
Self-organization of temporal pattern 
        generation based on anticipation.<CITE> Proceedings of  
WCNN-94</CITE>, pp. IV.149-154.  
<br><br>

<LI>Wang D.L. (1993): 
Modeling global synchrony in the visual cortex by 
        locally coupled neural oscillators. <CITE> Proceedings of the 15th 
Annual Conference of the Cognitive Science Society</CITE>, pp. 1058-1063. 
Boulder, CO. 
<br><br>

<LI>Wang D.L. (1993): 
Modeling stimulus specific habituation: The role of 
        primordial hippocampus. In: Eeckman F.H. and Bower J.M. (eds.), 
        <CITE>Proceedings of CNS-92</CITE>, pp. 103-107, 
Kluwer, Boston.
<br><br>

<LI>Wang D.L. (1993):
 A neural architecture for complex temporal pattern 
        generation. <CITE>Proceedings of the 3rd International Conference for 
        Young Computer Scientists</CITE>, pp. 3.25-3.38, Beijing.
<br><br>

<LI>Wang D.L. (1993): 
Global phase synchrony in the visual cortex: A local 
        mechanism. <CITE>Proceedings of WCNN-93</CITE>, pp. I29-I32. 
<br><br>

<LI>Wang D.L. and Arbib M.A. (1991): 
Hierarchical dishabituation of visual 
        discrimination in toads. In: Meyer J.-A. and Wilson S. (eds), 
        <CITE>Simulation of adaptive behavior: From animals to animats</CITE>,
pp. 77-88, MIT Press, Cambridge, MA. 
<br><br>

<LI>Wang D.L. and Arbib M.A. (1991):
 A neural model of temporal sequence 
        generation with interval maintenance. <CITE>Proceedings of the 13th 
Annual Conference of the Cognitive Science Society</CITE>,  pp. 944-948. 
Chicago, IL.
<br><br>

<LI>Wang D.L. and Arbib M.A. (1990):
 Mechanisms of pattern discrimination in
 the toad's visual system. <CITE>IJCNN-90</CITE>,  pp. II.477-482. 
San Diego, CA.
<br><br>

<LI>Wang D.L. and Arbib M.A. (1990):
 A computational model of visual pattern
 discrimination in toads. <CITE>Proceedings of the 12th Annual Conference of 
the Cognitive Science Society</CITE>,  pp. 598-605. Cambridge, MA.
<br><br>

<LI>Wang D.L. (1989):
 An extended model of the Neocognitron for pattern 
        partitioning and pattern composition. <CITE>Proceedings of IJCNN-90
</CITE>,  pp. II.267-274.  Washington, DC. 
<br><br>

<LI>Wang D.L. and King I. (1988):
 Three neural models which process temporal
      information. In <CITE>Proceedings of the First Annual Conference of 
the International Neural Network Society</CITE>, pp.227, Boston, MA. 
<br>

</UL>
<H5><a TARGET=_self HREF="pubs_year.html#top">Top of Page</a></H5>


<!-- ############################ -->

<a Name = "report"></a>

<H3>Technical Reports</H3>

<UL>

<LI>Yang Y., Wang P., and Wang D.L. (2022):
<a href="https://arxiv.org/abs/2203.00725">
A conformer based acoustic model for robust automatic speech recognition</a>.
<cite>arXiv:2203.00725</cite>.
<br><br>

<LI>Pandey A., Xu B., Kumar A., Donley J., Calamia P., and Wang D.L. (2021):
<a href="https://arxiv.org/abs/2110.13130">
Multichannel speech enhancement without beamforming</a>.
<cite>arXiv:2110.13130</cite>.
<br><br>

<LI>Pandey A., Xu B., Kumar A., Donley J., Calamia P., and Wang D.L. (2021):
<a href="https://arxiv.org/abs/2110.11844">
TADRN: Triple-attentive dual-recurrent network for ad-hoc array multichannel speech enhancement</a>.
<cite>arXiv:2110.11844</cite>.
<br><br>

<LI>Pandey A., Xu B., Kumar A., Donley J., Calamia P., and Wang D.L. (2021):
<a href="https://arxiv.org/abs/2110.10757">
TPARN: Triple-path attentive recurrent network for time-domain multichannel speech enhancement</a>.
<cite>arXiv:2110.10757</cite>.
<br><br>

<LI>Taherian H., Tan K., and Wang D.L. (2021):
<a href="https://arxiv.org/abs/2110.04289">
Location-based training for multi-channel talker-independent speaker separation</a>.
<cite>arXiv:2110.04289</cite>.
<br><br>

<LI>Pandey A. and Wang D.L. (2021):
<a href="https://arxiv.org/abs/2105.12831">
Self-attending RNN for speech enhancement to improve cross-corpus generalization</a>.
<cite>arXiv:2105.12831</cite>.
<br><br>

<LI>Zhang H. and Wang D.L. (2021):
<a href="https://arxiv.org/abs/2103.02552">
Multi-channel and multi-microphone acoustic echo cancellation using a deep learning based approach</a>.
<cite>arXiv:2103.02552</cite>.
<br><br>

<LI>Pandey A. and Wang D.L. (2020):
<a href="https://arxiv.org/abs/2010.12713">
Dual-path self-attention RNN for real-time speech enhancement</a>.
<cite>arXiv:2010.12713</cite>.
<br><br>

<LI>Wang D.L. (2006):
<a href="http://www.scholarpedia.org/article/LEGION%3A_locally_excitatory_globally_inhibitory_oscillator_networks">
LEGION: locally excitatory globally inhibitory oscillator networks</a>.
<cite>Scholarpedia</cite>, 1(9): 1620.
<br><br>

</UL>
<H5><a TARGET=_self HREF="pubs_year.html#top">Top of Page</a></H5>


<ADDRESS>
<p>
Original: July 1995<br>
<!--Updated: Sept. 2017-->
</p>
</ADDRESS>
    </td>
  </tr>

<tr><td colspan=4 align=center>
<pre><p><a href="https://web.cse.ohio-state.edu/~dwang/pubs_topic.html">Publications by topic</a>      <a href="http://www.cse.ohio-state.edu/~dwang/">DeLiang Wang</a>     <a href="https://pnlwang.github.io/pnl/">Laboratory</a></p></pre>
</td></tr>

</table>

</BODY>
</HTML>
